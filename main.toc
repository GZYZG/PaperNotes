\babel@toc {english}{}
\contentsline {section}{List of Figures}{3}{section*.2}%
\contentsline {section}{\numberline {1}Surveys}{5}{section.1}%
\contentsline {subsection}{\numberline {1.1}A Comprehensive Survey on Graph Neural Network}{5}{subsection.1.1}%
\contentsline {paragraph}{GNNs分类}{5}{section*.3}%
\contentsline {subparagraph}{RecGNNs}{5}{section*.4}%
\contentsline {subparagraph}{ConvGNNs}{5}{section*.5}%
\contentsline {subparagraph}{GAEs}{6}{section*.6}%
\contentsline {subparagraph}{STGNNs}{6}{section*.7}%
\contentsline {paragraph}{GNNs应用}{6}{section*.8}%
\contentsline {subparagraph}{Computer Vision}{6}{section*.9}%
\contentsline {subparagraph}{Natural Language Processing}{7}{section*.10}%
\contentsline {subparagraph}{Traffic}{7}{section*.11}%
\contentsline {subparagraph}{Recommender system}{7}{section*.12}%
\contentsline {subparagraph}{Chemistry}{7}{section*.13}%
\contentsline {subparagraph}{Others}{7}{section*.14}%
\contentsline {paragraph}{GNNs模型评估}{7}{section*.15}%
\contentsline {paragraph}{常用数据集}{7}{section*.16}%
\contentsline {paragraph}{未来发展方向}{7}{section*.17}%
\contentsline {subparagraph}{Model Depth}{8}{section*.18}%
\contentsline {subparagraph}{Scalability trade-off}{8}{section*.19}%
\contentsline {subparagraph}{Hetergenity}{8}{section*.20}%
\contentsline {subparagraph}{Dynamicity}{9}{section*.21}%
\contentsline {subsection}{\numberline {1.2}The Emerging Field of Signal Processing on Graphs}{9}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Representation Learning: A Review and New Perspectives}{9}{subsection.1.3}%
\contentsline {paragraph}{表征学习的应用}{10}{section*.22}%
\contentsline {subparagraph}{语音识别与信号处理}{10}{section*.23}%
\contentsline {subparagraph}{目标识别}{10}{section*.24}%
\contentsline {subparagraph}{自然语言处理}{10}{section*.25}%
\contentsline {subparagraph}{多任务学习、迁移学习、领域适应}{10}{section*.26}%
\contentsline {paragraph}{表征学习中的Priors}{10}{section*.27}%
\contentsline {subparagraph}{Smothness}{10}{section*.28}%
\contentsline {subparagraph}{Multiple explanatory factors}{10}{section*.29}%
\contentsline {subparagraph}{A hierarchical organization of explanatory factors}{10}{section*.30}%
\contentsline {subparagraph}{Semi-supervised learning}{10}{section*.31}%
\contentsline {subparagraph}{Shared factors across tasks}{10}{section*.32}%
\contentsline {subparagraph}{Manifold}{10}{section*.33}%
\contentsline {subparagraph}{Natural clustering}{10}{section*.34}%
\contentsline {subparagraph}{Temporal and spatial coherence}{10}{section*.35}%
\contentsline {subparagraph}{Sparsity}{11}{section*.36}%
\contentsline {subparagraph}{Simplicity of factor dependencies}{11}{section*.37}%
\contentsline {paragraph}{What makes a Representation Good?}{11}{section*.38}%
\contentsline {subparagraph}{Distributed representation}{11}{section*.39}%
\contentsline {subparagraph}{Depth and Abstraction}{11}{section*.40}%
\contentsline {subparagraph}{Disentangling Factors of Variation}{11}{section*.41}%
\contentsline {subparagraph}{Good Criteria for Learning Representation?}{11}{section*.42}%
\contentsline {section}{\numberline {2}DL / ML theory}{12}{section.2}%
\contentsline {subsection}{\numberline {2.1}Auto-Encoding Variational Bayes}{12}{subsection.2.1}%
\contentsline {paragraph}{方法解决的问题/优势}{14}{section*.43}%
\contentsline {paragraph}{方法的局限性/未来方向}{14}{section*.44}%
\contentsline {subsection}{\numberline {2.2}Adversarial Autoencoders}{14}{subsection.2.2}%
\contentsline {paragraph}{AAE思路}{14}{section*.45}%
\contentsline {paragraph}{AAE的应用}{15}{section*.46}%
\contentsline {paragraph}{方法解决的问题/优势}{15}{section*.47}%
\contentsline {paragraph}{方法的局限性/未来方向}{15}{section*.48}%
\contentsline {subsection}{\numberline {2.3}Attention is All you need}{16}{subsection.2.3}%
\contentsline {paragraph}{问题定义}{16}{section*.49}%
\contentsline {paragraph}{Transformer}{16}{figure.8}%
\contentsline {subparagraph}{Encoder and Decoder}{16}{section*.51}%
\contentsline {subparagraph}{Attention}{16}{section*.52}%
\contentsline {paragraph}{Why Self-Attention}{18}{section*.53}%
\contentsline {paragraph}{方法解决的问题/优势}{18}{section*.54}%
\contentsline {paragraph}{Attention参考资料}{19}{section*.55}%
\contentsline {subsection}{\numberline {2.4}Deep Residual Learning for Image Recognition}{19}{subsection.2.4}%
\contentsline {paragraph}{问题定义}{19}{section*.56}%
\contentsline {paragraph}{Residual Learning}{20}{figure.12}%
\contentsline {paragraph}{方法的问题/优势}{20}{section*.58}%
\contentsline {paragraph}{方法的局限性/未来方向}{20}{section*.59}%
\contentsline {section}{\numberline {3}GNN Theory}{21}{section.3}%
\contentsline {subsection}{\numberline {3.1}Variational Graph Auto-Encoders}{21}{subsection.3.1}%
\contentsline {paragraph}{VGAE思路}{21}{section*.60}%
\contentsline {paragraph}{方法解决的问题/优势}{21}{section*.61}%
\contentsline {paragraph}{方法的局限性/未来方向}{21}{section*.62}%
\contentsline {subsection}{\numberline {3.2}Rethinking pooling in graph neural networks}{21}{subsection.3.2}%
\contentsline {paragraph}{问题定义}{22}{section*.63}%
\contentsline {paragraph}{Rethinking思路}{22}{section*.64}%
\contentsline {paragraph}{方法解决的问题/优势}{22}{section*.65}%
\contentsline {paragraph}{方法的局限性/未来方向}{22}{section*.66}%
\contentsline {subsection}{\numberline {3.3}FASTGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling}{23}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning}{23}{subsection.3.4}%
\contentsline {paragraph}{问题定义}{23}{section*.67}%
\contentsline {paragraph}{思路}{23}{figure.14}%
\contentsline {subparagraph}{Semi-Supervised Contrastive Learning}{23}{section*.69}%
\contentsline {subparagraph}{Graph Generative Loss}{24}{section*.70}%
\contentsline {subparagraph}{Model Training}{24}{section*.71}%
\contentsline {paragraph}{方法解决的问题/优势}{25}{section*.72}%
\contentsline {paragraph}{方法的局限性/未来方向}{25}{section*.73}%
\contentsline {subsection}{\numberline {3.5}How powerful are graph gnns?}{25}{subsection.3.5}%
\contentsline {paragraph}{MEAN Learns Distributions}{25}{section*.74}%
\contentsline {paragraph}{MAX Identity "Skeleton"}{26}{section*.75}%
\contentsline {subsection}{\numberline {3.6}Inductive and Unsupervised Representation Learning on Graph Structured Objects}{27}{subsection.3.6}%
\contentsline {paragraph}{问题定义}{27}{section*.76}%
\contentsline {paragraph}{SEED思路}{27}{figure.16}%
\contentsline {subparagraph}{Sampling}{27}{section*.78}%
\contentsline {subparagraph}{Encoding}{28}{section*.79}%
\contentsline {subparagraph}{Embedding Distribution}{28}{section*.80}%
\contentsline {paragraph}{方法解决的问题/优势}{28}{section*.81}%
\contentsline {paragraph}{方法的局限性/未来方向}{28}{section*.82}%
\contentsline {subsection}{\numberline {3.7}DeepGCNs: Can GCNs Go as Deep as CNNs?}{29}{subsection.3.7}%
\contentsline {paragraph}{问题定义}{29}{figure.18}%
\contentsline {paragraph}{DeepGCN}{29}{section*.84}%
\contentsline {subparagraph}{Residual Learning for GCNs}{29}{section*.85}%
\contentsline {subparagraph}{Dense Connections in GCNs}{30}{section*.86}%
\contentsline {subparagraph}{Dilated Aggregation inn GCNs}{30}{section*.87}%
\contentsline {paragraph}{总结}{31}{section*.88}%
\contentsline {subsection}{\numberline {3.8}Gated Graph Sequence Neural Networks}{31}{subsection.3.8}%
\contentsline {paragraph}{GRU(Gated Recurrent Unit)}{31}{section*.89}%
\contentsline {paragraph}{GG-NN}{31}{section*.90}%
\contentsline {paragraph}{GGS-NN}{31}{section*.91}%
\contentsline {subsection}{\numberline {3.9}On the Bottleneck of Graph Neural Networks And Practical Implcation}{32}{subsection.3.9}%
\contentsline {paragraph}{Over Suqashing}{32}{figure.24}%
\contentsline {paragraph}{总结}{33}{section*.93}%
\contentsline {subsection}{\numberline {3.10}Hierarchical Graph Representation Learning with Differentiable Pooling}{34}{subsection.3.10}%
\contentsline {paragraph}{DIFFPOOL思路}{34}{section*.94}%
\contentsline {paragraph}{方法解决的问题/优势}{35}{section*.95}%
\contentsline {paragraph}{方法的局限性/未来方向}{35}{section*.96}%
\contentsline {subsection}{\numberline {3.11}Accurate, Efficient and Scalable Training of Graph Neural Networks}{35}{subsection.3.11}%
\contentsline {subsection}{\numberline {3.12}Towards Expressive Graph Representation}{35}{subsection.3.12}%
\contentsline {section}{\numberline {4}GNN Application}{36}{section.4}%
\contentsline {subsection}{\numberline {4.1}GraphRNN: Generating Realistic Graphs with Deep Auto-Regressive Models}{36}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Combining Label Propagation and Simple Models OUT-PERFORMS Graph Networks}{38}{subsection.4.2}%
\contentsline {paragraph}{问题定义}{38}{section*.97}%
\contentsline {paragraph}{Correct and Smooth}{38}{section*.98}%
\contentsline {subparagraph}{Simple Base Predictor}{39}{section*.99}%
\contentsline {subparagraph}{Correct error in base prediction with Residual Propagation}{39}{section*.100}%
\contentsline {subparagraph}{Smoothing final prediction with Prediction Correlation}{40}{section*.101}%
\contentsline {paragraph}{总结}{40}{section*.102}%
\contentsline {subsection}{\numberline {4.3}Graph Structure of Neural Networks}{40}{subsection.4.3}%
\contentsline {paragraph}{如何建模NN为图？}{40}{section*.103}%
\contentsline {paragraph}{方法解决的问题/优势}{40}{section*.104}%
\contentsline {paragraph}{方法的局限性/未来方向}{41}{section*.105}%
\contentsline {subsection}{\numberline {4.4}Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation}{41}{subsection.4.4}%
\contentsline {paragraph}{GCPN思路}{41}{section*.106}%
\contentsline {paragraph}{方法解决的问题/优势}{42}{section*.107}%
\contentsline {paragraph}{方法的局限性/未来方向}{42}{section*.108}%
\contentsline {subsection}{\numberline {4.5}Deep Graph random Process for Relational-Thinking-based Speech Recognition}{42}{subsection.4.5}%
\contentsline {paragraph}{问题定义}{42}{section*.109}%
\contentsline {paragraph}{DGP 思路}{42}{section*.110}%
\contentsline {paragraph}{实现细节}{43}{section*.111}%
\contentsline {subparagraph}{Deep Graph Random Process}{43}{section*.112}%
\contentsline {subparagraph}{Coupling of Innumerable Percept Graphs}{43}{section*.113}%
\contentsline {subparagraph}{Inference and Sampling of Edges of Summary Graph}{43}{section*.114}%
\contentsline {subparagraph}{Application of DGP for Acoustic Modelling}{43}{section*.115}%
\contentsline {subparagraph}{Learning}{44}{section*.116}%
\contentsline {paragraph}{方法解决的问题/优势}{44}{section*.117}%
\contentsline {paragraph}{方法的局限性/未来方向}{44}{section*.118}%
\contentsline {subsection}{\numberline {4.6}Learning to Represent Image and Text with Denotation Graph}{45}{subsection.4.6}%
\contentsline {subsection}{\numberline {4.7}Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{45}{subsection.4.7}%
\contentsline {section}{\numberline {5}Graph Similarity}{48}{section.5}%
\contentsline {subsection}{\numberline {5.1}graph2vec: Learning Distributed Representation of Graphs}{48}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Convolutional Set Macthing for Graph Similarity}{48}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}SimGNN: A Neural Network Approach to Fast Graph Similarity Computation}{50}{subsection.5.3}%
\contentsline {paragraph}{Strategy 1}{50}{section*.119}%
\contentsline {subparagraph}{Stage 1}{50}{section*.120}%
\contentsline {subparagraph}{Stage 2}{50}{section*.121}%
\contentsline {subparagraph}{Stage 3}{51}{section*.122}%
\contentsline {subparagraph}{Stage 4}{51}{section*.123}%
\contentsline {paragraph}{Strategy 2}{51}{section*.124}%
\contentsline {paragraph}{方法解决的问题/优势}{51}{section*.125}%
\contentsline {paragraph}{方法的局限性/未来方向}{52}{section*.126}%
\contentsline {subsection}{\numberline {5.4}Unsupervised Inductive Graph-level Representation Learning via Grpah-Graph proximity}{52}{subsection.5.4}%
\contentsline {paragraph}{UGraphEmb思路}{52}{section*.127}%
\contentsline {paragraph}{方法解决的问题/优势}{53}{section*.128}%
\contentsline {paragraph}{方法的局限性/未来方向}{53}{section*.129}%
\contentsline {subsection}{\numberline {5.5}Grapg-Graph Similarity Network}{53}{subsection.5.5}%
\contentsline {paragraph}{G2G思路}{53}{section*.130}%
\contentsline {subparagraph}{GCN}{54}{section*.131}%
\contentsline {subparagraph}{Heterogeneous Space Alignment}{54}{section*.132}%
\contentsline {subparagraph}{Graph-Graph Similarity Network}{54}{section*.133}%
\contentsline {subparagraph}{SuperGraph}{54}{section*.134}%
\contentsline {paragraph}{方法解决的问题/优势}{54}{section*.135}%
\contentsline {paragraph}{方法的局限性/未来方向}{54}{section*.136}%
\contentsline {subsection}{\numberline {5.6}Deep Graph Similarity Learning: A Survey}{54}{subsection.5.6}%
\contentsline {subsection}{\numberline {5.7}Hierarchical Large-scale Graph Similarity Computation via Graph Coarsening and Matching}{56}{subsection.5.7}%
\contentsline {paragraph}{COSIM-GNN思路}{56}{section*.137}%
\contentsline {subparagraph}{Embedding}{56}{section*.138}%
\contentsline {subparagraph}{Coarsening}{56}{section*.139}%
\contentsline {subparagraph}{Matching}{56}{section*.140}%
\contentsline {paragraph}{方法解决的问题/优势}{56}{section*.141}%
\contentsline {paragraph}{方法的局限性/未来方向}{57}{section*.142}%
\contentsline {subsection}{\numberline {5.8}Deep Graph Kernels}{57}{subsection.5.8}%
\contentsline {paragraph}{使用Graph Kernels计算图相似性}{57}{section*.143}%
\contentsline {paragraph}{思路}{57}{section*.144}%
\contentsline {paragraph}{方法解决的问题/优势}{58}{section*.145}%
\contentsline {paragraph}{方法的局限性/未来方向}{58}{section*.146}%
\contentsline {section}{\numberline {6}Dynamic Graphs}{59}{section.6}%
\contentsline {subsection}{\numberline {6.1}EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs}{59}{subsection.6.1}%
\contentsline {paragraph}{问题定义}{59}{section*.147}%
\contentsline {paragraph}{EvolveGCN思路}{59}{section*.148}%
\contentsline {paragraph}{方法解决的问题/优势}{60}{section*.149}%
\contentsline {paragraph}{方法的局限性/未来方向}{60}{section*.150}%
\contentsline {subsection}{\numberline {6.2}Temporal Graph Networks for Deep Learning on Dynamic Graphs}{60}{subsection.6.2}%
\contentsline {paragraph}{问题定义}{60}{section*.151}%
\contentsline {paragraph}{TGN思路}{60}{section*.152}%
\contentsline {subparagraph}{Memory}{60}{section*.153}%
\contentsline {subparagraph}{Message Function}{61}{section*.154}%
\contentsline {subparagraph}{Message Aggregator}{61}{section*.155}%
\contentsline {subparagraph}{Memory Updater}{61}{section*.156}%
\contentsline {subparagraph}{Embeddings}{61}{section*.157}%
\contentsline {paragraph}{方法解决的问题/优势}{62}{section*.158}%
\contentsline {subsection}{\numberline {6.3}Inductive representation learning on Temporal Graphs}{62}{subsection.6.3}%
\contentsline {paragraph}{问题定义}{62}{section*.159}%
\contentsline {paragraph}{TGAT思路}{62}{section*.160}%
\contentsline {subparagraph}{self-attention}{62}{section*.161}%
\contentsline {subparagraph}{TGAT}{62}{section*.162}%
\contentsline {paragraph}{方法解决的问题/优势}{63}{section*.163}%
\contentsline {paragraph}{方法的局限性/未来方向}{63}{section*.164}%
\contentsline {subsection}{\numberline {6.4}DySAT: Deep Neural Representation Learning on Dynamic Graph via Self-Attention Networks}{63}{subsection.6.4}%
\contentsline {paragraph}{问题定义}{63}{section*.165}%
\contentsline {subparagraph}{dynamic graph}{63}{section*.166}%
\contentsline {paragraph}{DySAT思路}{64}{figure.43}%
\contentsline {subparagraph}{Structural Self-Attention}{64}{section*.168}%
\contentsline {subparagraph}{Temporal Self-Attention}{64}{section*.169}%
\contentsline {paragraph}{方法解决的问题/优势}{65}{section*.170}%
\contentsline {paragraph}{方法的局限性/未来方向}{65}{section*.171}%
\contentsline {subsection}{\numberline {6.5}Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recogonition}{65}{subsection.6.5}%
\contentsline {paragraph}{问题定义}{65}{section*.172}%
\contentsline {paragraph}{ST-GCN思路}{65}{figure.44}%
\contentsline {subparagraph}{Skeleton Graph Construction}{66}{section*.174}%
\contentsline {subparagraph}{Spatial Graph Convolutional Neural Network}{66}{section*.175}%
\contentsline {paragraph}{方法解决的问题/优势}{66}{section*.176}%
\contentsline {paragraph}{方法的局限性/未来方向}{66}{section*.177}%
\contentsline {subsection}{\numberline {6.6}Inductive Representation Learning In Temporal Networks via Causal Anonymous Walks}{66}{subsection.6.6}%
\contentsline {paragraph}{问题定义}{67}{section*.178}%
\contentsline {paragraph}{CAW思路}{67}{section*.179}%
\contentsline {subparagraph}{Causal Anonymous Walk}{67}{section*.180}%
\contentsline {subparagraph}{Neural Encoding for Causal Anonymous Walks}{68}{section*.181}%
\contentsline {paragraph}{方法解决的问题/优势}{69}{section*.182}%
\contentsline {paragraph}{方法的局限性/未来方向}{69}{section*.183}%
\contentsline {subsection}{\numberline {6.7}DISCRETE GRAPH STRUCTURE LEARNING FOR FORECASTING MULTIPLE TIME SERIES}{69}{subsection.6.7}%
\contentsline {paragraph}{问题定义}{69}{section*.184}%
\contentsline {paragraph}{GTS思路}{69}{figure.48}%
\contentsline {paragraph}{总结}{69}{section*.186}%
\contentsline {section}{\numberline {7}CV}{71}{section.7}%
\contentsline {subsection}{\numberline {7.1}U-Net: Convolutional Networks for Biomedical Image Segmentation}{71}{subsection.7.1}%
\contentsline {paragraph}{Motivation}{71}{section*.187}%
\contentsline {paragraph}{U-Net}{71}{section*.188}%
\contentsline {paragraph}{总结}{72}{section*.189}%
\contentsline {section}{\numberline {8}NLP}{73}{section.8}%
\contentsline {subsection}{\numberline {8.1}Embedding Words in Non-Vector Space with Unsupervised Graph Learning}{73}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks}{73}{subsection.8.2}%
\contentsline {section}{\numberline {9}Recommender System}{75}{section.9}%
\contentsline {subsection}{\numberline {9.1}Factorization Machines}{75}{subsection.9.1}%
\contentsline {paragraph}{问题定义}{75}{section*.190}%
\contentsline {paragraph}{FM}{75}{section*.191}%
\contentsline {paragraph}{总结}{76}{section*.192}%
\contentsline {subsection}{\numberline {9.2}Wide \& Deep Learning for Recommender Systems}{77}{subsection.9.2}%
\contentsline {paragraph}{问题定义}{77}{section*.193}%
\contentsline {paragraph}{Wide\&Deep}{77}{figure.52}%
\contentsline {subparagraph}{Wide Component}{77}{section*.195}%
\contentsline {subparagraph}{Deep Component}{77}{section*.196}%
\contentsline {subparagraph}{Joint of Wide and Deep}{77}{section*.197}%
\contentsline {paragraph}{总结}{77}{section*.198}%
\contentsline {subsection}{\numberline {9.3}Deep Neural Networks for YouTube Recommendations}{78}{subsection.9.3}%
\contentsline {paragraph}{问题定义}{78}{section*.199}%
\contentsline {paragraph}{CANDIDATE GENERATION}{78}{section*.200}%
\contentsline {subparagraph}{训练数据的生成}{79}{section*.201}%
\contentsline {subparagraph}{特殊的特征}{79}{section*.202}%
\contentsline {paragraph}{RANKING}{79}{section*.203}%
\contentsline {subparagraph}{特征表示}{80}{section*.204}%
\contentsline {paragraph}{总结}{80}{section*.205}%
\contentsline {subsection}{\numberline {9.4}Field-aware Factorization Machines for CTR Prediction}{80}{subsection.9.4}%
\contentsline {paragraph}{问题定义}{80}{section*.206}%
\contentsline {paragraph}{FFM}{81}{section*.207}%
\contentsline {paragraph}{为什么要field-aware？}{81}{section*.208}%
\contentsline {paragraph}{Assign field to feature}{81}{section*.209}%
\contentsline {paragraph}{总结}{82}{section*.210}%
\contentsline {subsection}{\numberline {9.5}DeepFM: A Factorization-Machine based Neural Network for CTR Prediction}{82}{subsection.9.5}%
\contentsline {paragraph}{问题定义}{82}{section*.211}%
\contentsline {paragraph}{DeepFM}{82}{section*.212}%
\contentsline {subparagraph}{FM Component}{82}{figure.58}%
\contentsline {subparagraph}{Deep Component}{82}{figure.59}%
\contentsline {paragraph}{总结}{83}{section*.215}%
\contentsline {subsection}{\numberline {9.6}Product-based Neural Networks for User Response Prediction}{83}{subsection.9.6}%
\contentsline {paragraph}{问题定义}{84}{section*.216}%
\contentsline {paragraph}{PNN}{84}{section*.217}%
\contentsline {paragraph}{关于Product操作}{85}{section*.218}%
\contentsline {paragraph}{总结}{86}{section*.219}%
\contentsline {subsection}{\numberline {9.7}Personalized Video Recommendation Using Rich Contents from Videos}{86}{subsection.9.7}%
\contentsline {paragraph}{问题定义}{86}{section*.220}%
\contentsline {paragraph}{xxx}{86}{section*.221}%
\contentsline {paragraph}{总结}{86}{section*.222}%
\contentsline {section}{\numberline {10}Knowledge Tracing}{87}{section.10}%
\contentsline {subsection}{\numberline {10.1}Deep Knowledge Tracing}{87}{subsection.10.1}%
\contentsline {paragraph}{问题定义}{87}{section*.223}%
\contentsline {paragraph}{DKT}{87}{section*.224}%
\contentsline {paragraph}{总结}{88}{section*.225}%
\contentsline {subsection}{\numberline {10.2}Graph-based Knowledge Tracing: Modeling Student Proficiency Using Graph Neural Network}{88}{subsection.10.2}%
\contentsline {paragraph}{问题定义}{88}{section*.226}%
\contentsline {paragraph}{GKT}{88}{section*.227}%
\contentsline {subparagraph}{工作流程}{89}{section*.228}%
\contentsline {subparagraph}{隐式的图结构}{89}{section*.229}%
\contentsline {paragraph}{总结}{89}{section*.230}%
\contentsline {subsection}{\numberline {10.3}Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing}{89}{subsection.10.3}%
\contentsline {paragraph}{问题定义}{90}{figure.65}%
\contentsline {paragraph}{SAINT}{90}{figure.66}%
\contentsline {paragraph}{总结}{90}{section*.233}%
\contentsline {subsection}{\numberline {10.4}Tracing Knowledge State with Individual Cognition and Acquisition Estimation}{91}{subsection.10.4}%
\contentsline {paragraph}{问题定义}{91}{section*.234}%
\contentsline {paragraph}{IEKT}{91}{section*.235}%
\contentsline {paragraph}{总结}{93}{section*.236}%
\contentsline {subsection}{\numberline {10.5}Federated Deep Knowledge Tracing}{93}{subsection.10.5}%
\contentsline {paragraph}{问题定义}{93}{section*.237}%
\contentsline {paragraph}{FDKT}{93}{section*.238}%
\contentsline {paragraph}{总结}{93}{section*.239}%
\contentsline {subsection}{\numberline {10.6}Learning Process-consistent Knowledge Tracing}{94}{subsection.10.6}%
\contentsline {paragraph}{问题定义}{94}{section*.240}%
\contentsline {paragraph}{LPKT}{94}{section*.241}%
\contentsline {paragraph}{总结}{95}{section*.242}%
\contentsline {subsection}{\numberline {10.7}Overview}{95}{subsection.10.7}%
\contentsline {paragraph}{Knowledge Tracing}{95}{section*.243}%
\contentsline {section}{\numberline {11}Others}{97}{section.11}%
\contentsline {subsection}{\numberline {11.1}Weakly-Supervised Disentanglement Without Compromises}{97}{subsection.11.1}%
\contentsline {paragraph}{解耦表征}{97}{section*.244}%
\contentsline {paragraph}{问题定义}{97}{section*.245}%
\contentsline {paragraph}{Disentangled Representation优点}{97}{section*.246}%
\contentsline {subsection}{\numberline {11.2}Representation Learning via Invariant Causal Mechanism}{98}{subsection.11.2}%
\contentsline {paragraph}{问题定义}{98}{section*.247}%
\contentsline {paragraph}{RELIC}{98}{figure.70}%
\contentsline {paragraph}{总结}{98}{section*.249}%
\contentsline {subsection}{\numberline {11.3}UNSUPERVISED REPRESENTATION LEARNING FOR TIME SERIES WITH TEMPORAL NEIGHBORHOOD CODING}{99}{subsection.11.3}%
\contentsline {paragraph}{问题定义}{99}{section*.250}%
\contentsline {paragraph}{TNC思路}{99}{figure.71}%
\contentsline {paragraph}{总结}{100}{section*.252}%
\contentsline {section}{References}{100}{section*.253}%
