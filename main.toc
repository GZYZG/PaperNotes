\babel@toc {english}{}
\contentsline {section}{List of Figures}{3}{section*.2}%
\contentsline {section}{\numberline {1}GraphRNN: Generating Realistic Graphs with Deep Auto-Regressive Models}{5}{section.1}%
\contentsline {section}{\numberline {2}How powerful are graph gnns?}{8}{section.2}%
\contentsline {paragraph}{MEAN Learns Distributions}{9}{section*.3}%
\contentsline {paragraph}{MAX Identity "Skeleton"}{9}{section*.4}%
\contentsline {section}{\numberline {3}Gated Graph Sequence Neural Networks}{10}{section.3}%
\contentsline {paragraph}{GRU(Gated Recurrent Unit)}{10}{section*.5}%
\contentsline {paragraph}{GG-NN}{10}{section*.6}%
\contentsline {paragraph}{GGS-NN}{11}{section*.7}%
\contentsline {section}{\numberline {4}Graph Structure of Neural Networks}{12}{section.4}%
\contentsline {paragraph}{如何建模NN为图？}{12}{section*.8}%
\contentsline {paragraph}{方法解决的问题/优势}{12}{section*.9}%
\contentsline {paragraph}{方法的局限性/未来方向}{12}{section*.10}%
\contentsline {section}{\numberline {5}Variational Graph Auto-Encoders}{13}{section.5}%
\contentsline {paragraph}{VGAE思路}{13}{section*.11}%
\contentsline {paragraph}{方法解决的问题/优势}{13}{section*.12}%
\contentsline {paragraph}{方法的局限性/未来方向}{13}{section*.13}%
\contentsline {section}{\numberline {6}Hierarchical Graph Representation Learning with Differentiable Pooling}{14}{section.6}%
\contentsline {paragraph}{DIFFPOOL思路}{14}{section*.14}%
\contentsline {paragraph}{方法解决的问题/优势}{14}{section*.15}%
\contentsline {paragraph}{方法的局限性/未来方向}{15}{section*.16}%
\contentsline {section}{\numberline {7}Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation}{15}{section.7}%
\contentsline {paragraph}{GCPN思路}{15}{section*.17}%
\contentsline {paragraph}{方法解决的问题/优势}{15}{section*.18}%
\contentsline {paragraph}{方法的局限性/未来方向}{16}{section*.19}%
\contentsline {section}{\numberline {8}Auto-Encoding Variational Bayes}{16}{section.8}%
\contentsline {paragraph}{方法解决的问题/优势}{17}{section*.20}%
\contentsline {paragraph}{方法的局限性/未来方向}{18}{section*.21}%
\contentsline {section}{\numberline {9}Deep Graph random Process for Relational-Thinking-based Speech Recognition}{18}{section.9}%
\contentsline {paragraph}{问题定义}{18}{section*.22}%
\contentsline {paragraph}{DGP 思路}{19}{section*.23}%
\contentsline {paragraph}{实现细节}{19}{section*.24}%
\contentsline {subparagraph}{Deep Graph Random Process}{19}{section*.25}%
\contentsline {subparagraph}{Coupling of Innumerable Percept Graphs}{19}{section*.26}%
\contentsline {subparagraph}{Inference and Sampling of Edges of Summary Graph}{20}{section*.27}%
\contentsline {subparagraph}{Application of DGP for Acoustic Modelling}{20}{section*.28}%
\contentsline {subparagraph}{Learning}{20}{section*.29}%
\contentsline {paragraph}{方法解决的问题/优势}{20}{section*.30}%
\contentsline {paragraph}{方法的局限性/未来方向}{21}{section*.31}%
\contentsline {section}{\numberline {10}Adversarial Autoencoders}{21}{section.10}%
\contentsline {paragraph}{AAE思路}{22}{section*.32}%
\contentsline {paragraph}{AAE的应用}{22}{section*.33}%
\contentsline {paragraph}{方法解决的问题/优势}{23}{section*.34}%
\contentsline {paragraph}{方法的局限性/未来方向}{23}{section*.35}%
\contentsline {section}{\numberline {11}A Comprehensive Survey on Graph Neural Network}{23}{section.11}%
\contentsline {paragraph}{GNNs分类}{23}{section*.36}%
\contentsline {subparagraph}{RecGNNs}{23}{section*.37}%
\contentsline {subparagraph}{ConvGNNs}{24}{section*.38}%
\contentsline {subparagraph}{GAEs}{25}{section*.39}%
\contentsline {subparagraph}{STGNNs}{25}{section*.40}%
\contentsline {paragraph}{GNNs应用}{26}{section*.41}%
\contentsline {subparagraph}{Computer Vision}{26}{section*.42}%
\contentsline {subparagraph}{Natural Language Processing}{26}{section*.43}%
\contentsline {subparagraph}{Traffic}{26}{section*.44}%
\contentsline {subparagraph}{Recommender system}{26}{section*.45}%
\contentsline {subparagraph}{Chemistry}{26}{section*.46}%
\contentsline {subparagraph}{Others}{26}{section*.47}%
\contentsline {paragraph}{GNNs模型评估}{26}{section*.48}%
\contentsline {paragraph}{常用数据集}{26}{section*.49}%
\contentsline {paragraph}{未来发展方向}{26}{section*.50}%
\contentsline {subparagraph}{Model Depth}{26}{section*.51}%
\contentsline {subparagraph}{Scalability trade-off}{26}{section*.52}%
\contentsline {subparagraph}{Hetergenity}{27}{section*.53}%
\contentsline {subparagraph}{Dynamicity}{27}{section*.54}%
\contentsline {section}{\numberline {12}The Emerging Field of Signal Processing on Graphs}{27}{section.12}%
\contentsline {section}{\numberline {13}Rethinking pooling in graph neural networks}{28}{section.13}%
\contentsline {paragraph}{问题定义}{28}{section*.55}%
\contentsline {paragraph}{Rethinking思路}{28}{section*.56}%
\contentsline {paragraph}{方法解决的问题/优势}{29}{section*.57}%
\contentsline {paragraph}{方法的局限性/未来方向}{29}{section*.58}%
\contentsline {section}{\numberline {14}FASTGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling}{29}{section.14}%
\contentsline {section}{\numberline {15}Weakly-Supervised Disentanglement Without Compromises}{29}{section.15}%
\contentsline {paragraph}{解耦表征}{30}{section*.59}%
\contentsline {paragraph}{问题定义}{30}{section*.60}%
\contentsline {paragraph}{Disentangled Representation优点}{30}{section*.61}%
\contentsline {section}{\numberline {16}Representation Learning: A Review and New Perspectives}{30}{section.16}%
\contentsline {paragraph}{表征学习的应用}{31}{section*.62}%
\contentsline {subparagraph}{语音识别与信号处理}{31}{section*.63}%
\contentsline {subparagraph}{目标识别}{31}{section*.64}%
\contentsline {subparagraph}{自然语言处理}{31}{section*.65}%
\contentsline {subparagraph}{多任务学习、迁移学习、领域适应}{31}{section*.66}%
\contentsline {paragraph}{表征学习中的Priors}{31}{section*.67}%
\contentsline {subparagraph}{Smothness}{31}{section*.68}%
\contentsline {subparagraph}{Multiple explanatory factors}{31}{section*.69}%
\contentsline {subparagraph}{A hierarchical organization of explanatory factors}{31}{section*.70}%
\contentsline {subparagraph}{Semi-supervised learning}{31}{section*.71}%
\contentsline {subparagraph}{Shared factors across tasks}{31}{section*.72}%
\contentsline {subparagraph}{Manifold}{31}{section*.73}%
\contentsline {subparagraph}{Natural clustering}{31}{section*.74}%
\contentsline {subparagraph}{Temporal and spatial coherence}{31}{section*.75}%
\contentsline {subparagraph}{Sparsity}{31}{section*.76}%
\contentsline {subparagraph}{Simplicity of factor dependencies}{31}{section*.77}%
\contentsline {paragraph}{What makes a Representation Good?}{32}{section*.78}%
\contentsline {subparagraph}{Distributed representation}{32}{section*.79}%
\contentsline {subparagraph}{Depth and Abstraction}{32}{section*.80}%
\contentsline {subparagraph}{Disentangling Factors of Variation}{32}{section*.81}%
\contentsline {subparagraph}{Good Criteria for Learning Representation?}{32}{section*.82}%
\contentsline {section}{\numberline {17}Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning}{32}{section.17}%
\contentsline {paragraph}{问题定义}{32}{section*.83}%
\contentsline {paragraph}{思路}{32}{figure.17}%
\contentsline {subparagraph}{Semi-Supervised Contrastive Learning}{33}{section*.85}%
\contentsline {subparagraph}{Graph Generative Loss}{33}{section*.86}%
\contentsline {subparagraph}{Model Training}{34}{section*.87}%
\contentsline {paragraph}{方法解决的问题/优势}{34}{section*.88}%
\contentsline {paragraph}{方法的局限性/未来方向}{34}{section*.89}%
\contentsline {section}{\numberline {18}Inductive and Unsupervised Representation Learning on Graph Structured Objects}{34}{section.18}%
\contentsline {paragraph}{问题定义}{34}{section*.90}%
\contentsline {paragraph}{SEED思路}{34}{figure.18}%
\contentsline {subparagraph}{Sampling}{35}{section*.92}%
\contentsline {subparagraph}{Encoding}{35}{section*.93}%
\contentsline {subparagraph}{Embedding Distribution}{35}{section*.94}%
\contentsline {paragraph}{方法解决的问题/优势}{35}{section*.95}%
\contentsline {paragraph}{方法的局限性/未来方向}{36}{section*.96}%
\contentsline {section}{\numberline {19}Attention is All you need}{36}{section.19}%
\contentsline {paragraph}{问题定义}{36}{section*.97}%
\contentsline {paragraph}{Transformer}{36}{figure.20}%
\contentsline {subparagraph}{Encoder and Decoder}{36}{section*.99}%
\contentsline {subparagraph}{Attention}{37}{section*.100}%
\contentsline {paragraph}{Why Self-Attention}{38}{section*.101}%
\contentsline {paragraph}{方法解决的问题/优势}{39}{section*.102}%
\contentsline {paragraph}{Attention参考资料}{39}{section*.103}%
\contentsline {section}{\numberline {20}Deep Residual Learning for Image Recognition}{39}{section.20}%
\contentsline {paragraph}{问题定义}{39}{section*.104}%
\contentsline {paragraph}{Residual Learning}{40}{figure.24}%
\contentsline {paragraph}{方法的问题/优势}{40}{section*.106}%
\contentsline {paragraph}{方法的局限性/未来方向}{40}{section*.107}%
\contentsline {section}{\numberline {21}DeepGCNs: Can GCNs Go as Deep as CNNs?}{41}{section.21}%
\contentsline {paragraph}{问题定义}{41}{figure.25}%
\contentsline {paragraph}{DeepGCN}{41}{section*.109}%
\contentsline {subparagraph}{Residual Learning for GCNs}{41}{section*.110}%
\contentsline {subparagraph}{Dense Connections in GCNs}{42}{section*.111}%
\contentsline {subparagraph}{Dilated Aggregation inn GCNs}{42}{section*.112}%
\contentsline {paragraph}{总结}{43}{section*.113}%
\contentsline {section}{\numberline {22}Combining Label Propagation and Simple Models OUT-PERFORMS Graph Networks}{43}{section.22}%
\contentsline {paragraph}{问题定义}{43}{section*.114}%
\contentsline {paragraph}{Correct and Smooth}{43}{section*.115}%
\contentsline {subparagraph}{Simple Base Predictor}{43}{section*.116}%
\contentsline {subparagraph}{Correct error in base prediction with Residual Propagation}{43}{section*.117}%
\contentsline {subparagraph}{Smoothing final prediction with Prediction Correlation}{44}{section*.118}%
\contentsline {paragraph}{总结}{44}{section*.119}%
\contentsline {section}{\numberline {23}On the Bottleneck of Graph Neural Networks And Practical Implcation}{45}{section.23}%
\contentsline {paragraph}{Over Suqashing}{45}{figure.29}%
\contentsline {paragraph}{总结}{45}{section*.121}%
\contentsline {section}{\numberline {24}Representation Learning via Invariant Causal Mechanism}{46}{section.24}%
\contentsline {paragraph}{问题定义}{46}{section*.122}%
\contentsline {paragraph}{RELIC}{46}{figure.30}%
\contentsline {paragraph}{总结}{47}{section*.124}%
\contentsline {section}{\numberline {25}U-Net: Convolutional Networks for Biomedical Image Segmentation}{47}{section.25}%
\contentsline {paragraph}{Motivation}{47}{section*.125}%
\contentsline {paragraph}{U-Net}{47}{section*.126}%
\contentsline {paragraph}{总结}{48}{section*.127}%
\contentsline {section}{\numberline {26}UNSUPERVISED REPRESENTATION LEARNING FOR TIME SERIES WITH TEMPORAL NEIGHBORHOOD CODING}{48}{section.26}%
\contentsline {paragraph}{问题定义}{49}{section*.128}%
\contentsline {paragraph}{TNC思路}{49}{figure.33}%
\contentsline {paragraph}{总结}{50}{section*.130}%
\contentsline {section}{\numberline {27}Graph Similarity}{50}{section.27}%
\contentsline {subsection}{\numberline {27.1}graph2vec: Learning Distributed Representation of Graphs}{50}{subsection.27.1}%
\contentsline {subsection}{\numberline {27.2}Convolutional Set Macthing for Graph Similarity}{51}{subsection.27.2}%
\contentsline {subsection}{\numberline {27.3}SimGNN: A Neural Network Approach to Fast Graph Similarity Computation}{53}{subsection.27.3}%
\contentsline {paragraph}{Strategy 1}{53}{section*.131}%
\contentsline {subparagraph}{Stage 1}{53}{section*.132}%
\contentsline {subparagraph}{Stage 2}{53}{section*.133}%
\contentsline {subparagraph}{Stage 3}{54}{section*.134}%
\contentsline {subparagraph}{Stage 4}{54}{section*.135}%
\contentsline {paragraph}{Strategy 2}{54}{section*.136}%
\contentsline {paragraph}{方法解决的问题/优势}{54}{section*.137}%
\contentsline {paragraph}{方法的局限性/未来方向}{54}{section*.138}%
\contentsline {subsection}{\numberline {27.4}Unsupervised Inductive Graph-level Representation Learning via Grpah-Graph proximity}{55}{subsection.27.4}%
\contentsline {paragraph}{UGraphEmb思路}{55}{section*.139}%
\contentsline {paragraph}{方法解决的问题/优势}{55}{section*.140}%
\contentsline {paragraph}{方法的局限性/未来方向}{56}{section*.141}%
\contentsline {subsection}{\numberline {27.5}Grapg-Graph Similarity Network}{56}{subsection.27.5}%
\contentsline {paragraph}{G2G思路}{56}{section*.142}%
\contentsline {subparagraph}{GCN}{56}{section*.143}%
\contentsline {subparagraph}{Heterogeneous Space Alignment}{56}{section*.144}%
\contentsline {subparagraph}{Graph-Graph Similarity Network}{56}{section*.145}%
\contentsline {subparagraph}{SuperGraph}{56}{section*.146}%
\contentsline {paragraph}{方法解决的问题/优势}{57}{section*.147}%
\contentsline {paragraph}{方法的局限性/未来方向}{57}{section*.148}%
\contentsline {subsection}{\numberline {27.6}Deep Graph Similarity Learning: A Survey}{57}{subsection.27.6}%
\contentsline {subsection}{\numberline {27.7}Hierarchical Large-scale Graph Similarity Computation via Graph Coarsening and Matching}{58}{subsection.27.7}%
\contentsline {paragraph}{COSIM-GNN思路}{59}{section*.149}%
\contentsline {subparagraph}{Embedding}{59}{section*.150}%
\contentsline {subparagraph}{Coarsening}{59}{section*.151}%
\contentsline {subparagraph}{Matching}{59}{section*.152}%
\contentsline {paragraph}{方法解决的问题/优势}{59}{section*.153}%
\contentsline {paragraph}{方法的局限性/未来方向}{59}{section*.154}%
\contentsline {subsection}{\numberline {27.8}Deep Graph Kernels}{59}{subsection.27.8}%
\contentsline {paragraph}{使用Graph Kernels计算图相似性}{60}{section*.155}%
\contentsline {paragraph}{思路}{60}{section*.156}%
\contentsline {paragraph}{方法解决的问题/优势}{60}{section*.157}%
\contentsline {paragraph}{方法的局限性/未来方向}{60}{section*.158}%
\contentsline {section}{\numberline {28}Dynamic Graphs}{61}{section.28}%
\contentsline {subsection}{\numberline {28.1}EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs}{61}{subsection.28.1}%
\contentsline {paragraph}{问题定义}{61}{section*.159}%
\contentsline {paragraph}{EvolveGCN思路}{61}{section*.160}%
\contentsline {paragraph}{方法解决的问题/优势}{62}{section*.161}%
\contentsline {paragraph}{方法的局限性/未来方向}{62}{section*.162}%
\contentsline {subsection}{\numberline {28.2}Temporal Graph Networks for Deep Learning on Dynamic Graphs}{62}{subsection.28.2}%
\contentsline {paragraph}{问题定义}{62}{section*.163}%
\contentsline {paragraph}{TGN思路}{62}{section*.164}%
\contentsline {subparagraph}{Memory}{62}{section*.165}%
\contentsline {subparagraph}{Message Function}{63}{section*.166}%
\contentsline {subparagraph}{Message Aggregator}{63}{section*.167}%
\contentsline {subparagraph}{Memory Updater}{63}{section*.168}%
\contentsline {subparagraph}{Embeddings}{63}{section*.169}%
\contentsline {paragraph}{方法解决的问题/优势}{64}{section*.170}%
\contentsline {subsection}{\numberline {28.3}Inductive representation learning on Temporal Graphs}{64}{subsection.28.3}%
\contentsline {paragraph}{问题定义}{64}{section*.171}%
\contentsline {paragraph}{TGAT思路}{64}{section*.172}%
\contentsline {subparagraph}{self-attention}{64}{section*.173}%
\contentsline {subparagraph}{TGAT}{64}{section*.174}%
\contentsline {paragraph}{方法解决的问题/优势}{65}{section*.175}%
\contentsline {paragraph}{方法的局限性/未来方向}{65}{section*.176}%
\contentsline {subsection}{\numberline {28.4}DySAT: Deep Neural Representation Learning on Dynamic Graph via Self-Attention Networks}{65}{subsection.28.4}%
\contentsline {paragraph}{问题定义}{65}{section*.177}%
\contentsline {subparagraph}{dynamic graph}{65}{section*.178}%
\contentsline {paragraph}{DySAT思路}{66}{figure.44}%
\contentsline {subparagraph}{Structural Self-Attention}{66}{section*.180}%
\contentsline {subparagraph}{Temporal Self-Attention}{66}{section*.181}%
\contentsline {paragraph}{方法解决的问题/优势}{67}{section*.182}%
\contentsline {paragraph}{方法的局限性/未来方向}{67}{section*.183}%
\contentsline {subsection}{\numberline {28.5}Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recogonition}{67}{subsection.28.5}%
\contentsline {paragraph}{问题定义}{67}{section*.184}%
\contentsline {paragraph}{ST-GCN思路}{67}{figure.45}%
\contentsline {subparagraph}{Skeleton Graph Construction}{68}{section*.186}%
\contentsline {subparagraph}{Spatial Graph Convolutional Neural Network}{68}{section*.187}%
\contentsline {paragraph}{方法解决的问题/优势}{68}{section*.188}%
\contentsline {paragraph}{方法的局限性/未来方向}{68}{section*.189}%
\contentsline {subsection}{\numberline {28.6}Inductive Representation Learning In Temporal Networks via Causal Anonymous Walks}{68}{subsection.28.6}%
\contentsline {paragraph}{问题定义}{69}{section*.190}%
\contentsline {paragraph}{CAW思路}{69}{section*.191}%
\contentsline {subparagraph}{Causal Anonymous Walk}{69}{section*.192}%
\contentsline {subparagraph}{Neural Encoding for Causal Anonymous Walks}{70}{section*.193}%
\contentsline {paragraph}{方法解决的问题/优势}{71}{section*.194}%
\contentsline {paragraph}{方法的局限性/未来方向}{71}{section*.195}%
\contentsline {subsection}{\numberline {28.7}DISCRETE GRAPH STRUCTURE LEARNING FOR FORECASTING MULTIPLE TIME SERIES}{71}{subsection.28.7}%
\contentsline {paragraph}{问题定义}{71}{section*.196}%
\contentsline {paragraph}{GTS思路}{72}{figure.49}%
\contentsline {paragraph}{总结}{72}{section*.198}%
\contentsline {section}{\numberline {29}Recommender System}{72}{section.29}%
\contentsline {subsection}{\numberline {29.1}Factorization Machines}{72}{subsection.29.1}%
\contentsline {paragraph}{问题定义}{72}{section*.199}%
\contentsline {paragraph}{FM}{72}{section*.200}%
\contentsline {paragraph}{总结}{74}{section*.201}%
\contentsline {subsection}{\numberline {29.2}Wide \& Deep Learning for Recommender Systems}{74}{subsection.29.2}%
\contentsline {paragraph}{问题定义}{74}{section*.202}%
\contentsline {paragraph}{Wide\&Deep}{74}{figure.50}%
\contentsline {subparagraph}{Wide Component}{74}{section*.204}%
\contentsline {subparagraph}{Deep Component}{74}{section*.205}%
\contentsline {subparagraph}{Joint of Wide and Deep}{75}{section*.206}%
\contentsline {paragraph}{总结}{75}{section*.207}%
\contentsline {subsection}{\numberline {29.3}Deep Neural Networks for YouTube Recommendations}{75}{subsection.29.3}%
\contentsline {paragraph}{问题定义}{75}{section*.208}%
\contentsline {paragraph}{CANDIDATE GENERATION}{76}{section*.209}%
\contentsline {subparagraph}{训练数据的生成}{76}{section*.210}%
\contentsline {subparagraph}{特殊的特征}{76}{section*.211}%
\contentsline {paragraph}{RANKING}{77}{section*.212}%
\contentsline {subparagraph}{特征表示}{77}{section*.213}%
\contentsline {paragraph}{总结}{77}{section*.214}%
\contentsline {subsection}{\numberline {29.4}Field-aware Factorization Machines for CTR Prediction}{77}{subsection.29.4}%
\contentsline {paragraph}{问题定义}{78}{section*.215}%
\contentsline {paragraph}{FFM}{78}{section*.216}%
\contentsline {paragraph}{为什么要field-aware？}{78}{section*.217}%
\contentsline {paragraph}{Assign field to feature}{79}{section*.218}%
\contentsline {paragraph}{总结}{79}{section*.219}%
\contentsline {subsection}{\numberline {29.5}DeepFM: A Factorization-Machine based Neural Network for CTR Prediction}{79}{subsection.29.5}%
\contentsline {paragraph}{问题定义}{79}{section*.220}%
\contentsline {paragraph}{DeepFM}{79}{section*.221}%
\contentsline {subparagraph}{FM Component}{79}{figure.56}%
\contentsline {subparagraph}{Deep Component}{80}{figure.57}%
\contentsline {paragraph}{总结}{80}{section*.224}%
\contentsline {section}{\numberline {30}简读论文}{82}{section.30}%
\contentsline {subsection}{\numberline {30.1}Embedding Words in Non-Vector Space with Unsupervised Graph Learning}{82}{subsection.30.1}%
\contentsline {subsection}{\numberline {30.2}Accurate, Efficient and Scalable Training of Graph Neural Networks}{82}{subsection.30.2}%
\contentsline {subsection}{\numberline {30.3}Learning to Represent Image and Text with Denotation Graph}{82}{subsection.30.3}%
\contentsline {subsection}{\numberline {30.4}Towards Expressive Graph Representation}{83}{subsection.30.4}%
\contentsline {subsection}{\numberline {30.5}Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks}{83}{subsection.30.5}%
\contentsline {subsection}{\numberline {30.6}Editing Graphs to Satisfy Diversity Requirements}{84}{subsection.30.6}%
\contentsline {subsection}{\numberline {30.7}On the exact computation of the graph edit distance}{84}{subsection.30.7}%
\contentsline {subsection}{\numberline {30.8}Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{84}{subsection.30.8}%
\contentsline {section}{References}{85}{section*.225}%
