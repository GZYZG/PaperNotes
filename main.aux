\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{List of Figures}{3}{section*.2}\protected@file@percent }
\citation{9046288}
\citation{li2015gated}
\@writefile{toc}{\contentsline {section}{\numberline {1}Surveys}{5}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}A Comprehensive Survey on Graph Neural Network}{5}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GNNs分类}{5}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{RecGNNs}{5}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{ConvGNNs}{5}{section*.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces RecGNNs v.s. ConvGNNs}}{6}{figure.1}\protected@file@percent }
\newlabel{fig:recgnns_convgnns}{{1}{6}{RecGNNs v.s. ConvGNNs}{figure.1}{}}
\@writefile{toc}{\contentsline {subparagraph}{GAEs}{6}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{STGNNs}{6}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GNNs应用}{6}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Computer Vision}{6}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Difference between GCN and GAT}}{7}{figure.2}\protected@file@percent }
\newlabel{fig:gcn_gat}{{2}{7}{Difference between GCN and GAT}{figure.2}{}}
\@writefile{toc}{\contentsline {subparagraph}{Natural Language Processing}{7}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Traffic}{7}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Recommender system}{7}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Chemistry}{7}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Others}{7}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GNNs模型评估}{7}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{常用数据集}{7}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{未来发展方向}{7}{section*.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Main characteristics of selected GAEs}}{8}{figure.3}\protected@file@percent }
\newlabel{fig:gaes}{{3}{8}{Main characteristics of selected GAEs}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Summary of benchmark datasets}}{8}{figure.4}\protected@file@percent }
\newlabel{fig:benchmark}{{4}{8}{Summary of benchmark datasets}{figure.4}{}}
\@writefile{toc}{\contentsline {subparagraph}{Model Depth}{8}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Scalability trade-off}{8}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Hetergenity}{8}{section*.20}\protected@file@percent }
\citation{6494675}
\citation{6472238}
\@writefile{toc}{\contentsline {subparagraph}{Dynamicity}{9}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}The Emerging Field of Signal Processing on Graphs}{9}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Representation Learning: A Review and New Perspectives}{9}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{表征学习的应用}{10}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{语音识别与信号处理}{10}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{目标识别}{10}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{自然语言处理}{10}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{多任务学习、迁移学习、领域适应}{10}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{表征学习中的Priors}{10}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Smothness}{10}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Multiple explanatory factors}{10}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{A hierarchical organization of explanatory factors}{10}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Semi-supervised learning}{10}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Shared factors across tasks}{10}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Manifold}{10}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Natural clustering}{10}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Temporal and spatial coherence}{10}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Sparsity}{11}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Simplicity of factor dependencies}{11}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What makes a Representation Good?}{11}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Distributed representation}{11}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Depth and Abstraction}{11}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Disentangling Factors of Variation}{11}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Good Criteria for Learning Representation?}{11}{section*.42}\protected@file@percent }
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {section}{\numberline {2}DL / ML theory}{12}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Auto-Encoding Variational Bayes}{12}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 有向图模型}}{12}{figure.5}\protected@file@percent }
\newlabel{fig:aevb}{{5}{12}{有向图模型}{figure.5}{}}
\newlabel{eq:kl}{{1}{12}{Auto-Encoding Variational Bayes}{equation.2.1}{}}
\citation{doersch2016tutorial}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces without vs. with reparameterization}}{13}{figure.6}\protected@file@percent }
\newlabel{fig:vae_rp}{{6}{13}{without vs. with reparameterization}{figure.6}{}}
\citation{makhzani2016adversarial}
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{14}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{14}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Adversarial Autoencoders}{14}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Architecture of AAE}}{14}{figure.7}\protected@file@percent }
\newlabel{fig:AAE}{{7}{14}{Architecture of AAE}{figure.7}{}}
\@writefile{toc}{\contentsline {paragraph}{AAE思路}{14}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{AAE的应用}{15}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{15}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{15}{section*.48}\protected@file@percent }
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Attention is All you need}{16}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{16}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transformer}{16}{figure.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Encoder and Decoder}{16}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Attention}{16}{section*.52}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Transformer Architecture}}{17}{figure.8}\protected@file@percent }
\newlabel{fig:transformer}{{8}{17}{Transformer Architecture}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Scaled Dot-Production Attention与Multi-Head Attention}}{18}{figure.9}\protected@file@percent }
\newlabel{fig:scaled dot-product attention and multi-head attention}{{9}{18}{Scaled Dot-Production Attention与Multi-Head Attention}{figure.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Self-Attention}{18}{section*.53}\protected@file@percent }
\newlabel{rnn-cnn-attention}{{2.3}{18}{Why Self-Attention}{section*.53}{}}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{18}{section*.54}\protected@file@percent }
\citation{he2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces CNN、Attention、Multi-head Attention}}{19}{figure.10}\protected@file@percent }
\newlabel{fig:cnn-attention-multi head}{{10}{19}{CNN、Attention、Multi-head Attention}{figure.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Attention参考资料}{19}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Deep Residual Learning for Image Recognition}{19}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{19}{section*.56}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Degradation}}{19}{figure.11}\protected@file@percent }
\newlabel{fig:degradation}{{11}{19}{Degradation}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Residual learning: a building block}}{20}{figure.12}\protected@file@percent }
\newlabel{fig:residual}{{12}{20}{Residual learning: a building block}{figure.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Residual Learning}{20}{figure.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的问题/优势}{20}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{20}{section*.59}\protected@file@percent }
\citation{kipf2016variational}
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {section}{\numberline {3}GNN Theory}{21}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Variational Graph Auto-Encoders}{21}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces VGAE}}{21}{figure.13}\protected@file@percent }
\newlabel{fig:vgae}{{13}{21}{VGAE}{figure.13}{}}
\@writefile{toc}{\contentsline {paragraph}{VGAE思路}{21}{section*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{21}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{21}{section*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Rethinking pooling in graph neural networks}{21}{subsection.3.2}\protected@file@percent }
\citation{mesquita2020rethinking}
\citation{dhillon2007weighted}
\citation{ying2019hierarchical}
\citation{khasahmadi2020memory-based}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{22}{section*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Rethinking思路}{22}{section*.64}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{22}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{22}{section*.66}\protected@file@percent }
\citation{chen2018fastgcn}
\citation{wan2020contrastive}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}FASTGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling}{23}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning}{23}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{23}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{思路}{23}{figure.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Semi-Supervised Contrastive Learning}{23}{section*.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces CG3}}{24}{figure.14}\protected@file@percent }
\newlabel{fig:cg3}{{14}{24}{CG3}{figure.14}{}}
\@writefile{toc}{\contentsline {subparagraph}{Graph Generative Loss}{24}{section*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Model Training}{24}{section*.71}\protected@file@percent }
\citation{xu2018how}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{25}{section*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{25}{section*.73}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}How powerful are graph gnns?}{25}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{MEAN Learns Distributions}{25}{section*.74}\protected@file@percent }
\citation{shervashidze2011weisfeiler}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces 令Mean, Max失败的例子}}{26}{figure.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{MAX Identity "Skeleton"}{26}{section*.75}\protected@file@percent }
\citation{SEED_Lichen}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Inductive and Unsupervised Representation Learning on Graph Structured Objects}{27}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{27}{section*.76}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces SEED}}{27}{figure.16}\protected@file@percent }
\newlabel{fig:seed}{{16}{27}{SEED}{figure.16}{}}
\@writefile{toc}{\contentsline {paragraph}{SEED思路}{27}{figure.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Sampling}{27}{section*.78}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces WEAVE与随机游走对比}}{27}{figure.17}\protected@file@percent }
\newlabel{fig:weave}{{17}{27}{WEAVE与随机游走对比}{figure.17}{}}
\@writefile{toc}{\contentsline {subparagraph}{Encoding}{28}{section*.79}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Embedding Distribution}{28}{section*.80}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{28}{section*.81}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{28}{section*.82}\protected@file@percent }
\citation{li2019deepgcns}
\citation{he2016deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}DeepGCNs: Can GCNs Go as Deep as CNNs?}{29}{subsection.3.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Traing deep GCNs}}{29}{figure.18}\protected@file@percent }
\newlabel{fig:traing_deep_gcns}{{18}{29}{Traing deep GCNs}{figure.18}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{29}{figure.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DeepGCN}{29}{section*.84}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Residual Learning for GCNs}{29}{section*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Dense Connections in GCNs}{30}{section*.86}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Dilated Aggregation inn GCNs}{30}{section*.87}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Dilated Convolution in GCNs}}{30}{figure.19}\protected@file@percent }
\newlabel{figz:dilated_convolution_in_gcns}{{19}{30}{Dilated Convolution in GCNs}{figure.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces DeepGCN}}{30}{figure.20}\protected@file@percent }
\newlabel{figz:deepgcn}{{20}{30}{DeepGCN}{figure.20}{}}
\citation{li2015gated}
\citation{cho2014learning}
\citation{weston2015aicomplete}
\citation{cho2014learning}
\citation{10.1007/3-540-44802-0_1}
\@writefile{toc}{\contentsline {paragraph}{总结}{31}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Gated Graph Sequence Neural Networks}{31}{subsection.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GRU(Gated Recurrent Unit)}{31}{section*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GG-NN}{31}{section*.90}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GGS-NN}{31}{section*.91}\protected@file@percent }
\citation{alon2021on}
\newlabel{fig:lstm_cell}{{21(a)}{32}{Subfigure 21(a)}{subfigure.21.1}{}}
\newlabel{sub@fig:lstm_cell}{{(a)}{32}{Subfigure 21(a)\relax }{subfigure.21.1}{}}
\newlabel{fig:gru_cell}{{21(b)}{32}{Subfigure 21(b)}{subfigure.21.2}{}}
\newlabel{sub@fig:gru_cell}{{(b)}{32}{Subfigure 21(b)\relax }{subfigure.21.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces LSTM 和 GRU cell的内部结构}}{32}{figure.21}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {LSTM cell}}}{32}{figure.21}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GRU cell}}}{32}{figure.21}\protected@file@percent }
\newlabel{fig:cell}{{21}{32}{LSTM 和 GRU cell的内部结构}{figure.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}On the Bottleneck of Graph Neural Networks And Practical Implcation}{32}{subsection.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Over Suqashing}{32}{figure.24}\protected@file@percent }
\citation{li2019deepgcns}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces GG-NN}}{33}{figure.22}\protected@file@percent }
\newlabel{fig:gg-nn}{{22}{33}{GG-NN}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces GGS-NN}}{33}{figure.23}\protected@file@percent }
\newlabel{fig:ggs-nn}{{23}{33}{GGS-NN}{figure.23}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{33}{section*.93}\protected@file@percent }
\citation{ying2019hierarchical}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces The bottlenecks of Seq2seq and GNN models}}{34}{figure.24}\protected@file@percent }
\newlabel{fig:bottleneck}{{24}{34}{The bottlenecks of Seq2seq and GNN models}{figure.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10}Hierarchical Graph Representation Learning with Differentiable Pooling}{34}{subsection.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Overview of DIFFPOOL}}{34}{figure.25}\protected@file@percent }
\newlabel{fig:diffpool}{{25}{34}{Overview of DIFFPOOL}{figure.25}{}}
\@writefile{toc}{\contentsline {paragraph}{DIFFPOOL思路}{34}{section*.94}\protected@file@percent }
\citation{Zeng_2021}
\citation{mao2020expressive}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{35}{section*.95}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{35}{section*.96}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.11}Accurate, Efficient and Scalable Training of Graph Neural Networks}{35}{subsection.3.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.12}Towards Expressive Graph Representation}{35}{subsection.3.12}\protected@file@percent }
\citation{you2018graphrnn}
\citation{kingma2014auto}
\citation{goodfellow2014generative}
\citation{simonovsky2018graphvae}
\citation{li2018learning}
\citation{li2018learning}
\@writefile{toc}{\contentsline {section}{\numberline {4}GNN Application}{36}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}GraphRNN: Generating Realistic Graphs with Deep Auto-Regressive Models}{36}{subsection.4.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces GraphRNN inference algorithm }}{37}{algorithm.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces GraphRNN生成图的过程}}{37}{figure.26}\protected@file@percent }
\citation{huang2020combining}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Combining Label Propagation and Simple Models OUT-PERFORMS Graph Networks}{38}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{38}{section*.97}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Correct and Smooth}{38}{section*.98}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Correct and Smooth}}{39}{figure.27}\protected@file@percent }
\newlabel{fig:C&S}{{27}{39}{Correct and Smooth}{figure.27}{}}
\@writefile{toc}{\contentsline {subparagraph}{Simple Base Predictor}{39}{section*.99}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Correct error in base prediction with Residual Propagation}{39}{section*.100}\protected@file@percent }
\citation{you2020graph}
\@writefile{toc}{\contentsline {subparagraph}{Smoothing final prediction with Prediction Correlation}{40}{section*.101}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{40}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Graph Structure of Neural Networks}{40}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{如何建模NN为图？}{40}{section*.103}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{40}{section*.104}\protected@file@percent }
\citation{you2019graph}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{41}{section*.105}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation}{41}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Overview of GCPN}}{41}{figure.28}\protected@file@percent }
\newlabel{fig:gcpn}{{28}{41}{Overview of GCPN}{figure.28}{}}
\@writefile{toc}{\contentsline {paragraph}{GCPN思路}{41}{section*.106}\protected@file@percent }
\citation{dgp}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{42}{section*.107}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{42}{section*.108}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Deep Graph random Process for Relational-Thinking-based Speech Recognition}{42}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{42}{section*.109}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DGP 思路}{42}{section*.110}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实现细节}{43}{section*.111}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Deep Graph Random Process}{43}{section*.112}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Coupling of Innumerable Percept Graphs}{43}{section*.113}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Inference and Sampling of Edges of Summary Graph}{43}{section*.114}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Application of DGP for Acoustic Modelling}{43}{section*.115}\protected@file@percent }
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {subparagraph}{Learning}{44}{section*.116}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{44}{section*.117}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{44}{section*.118}\protected@file@percent }
\citation{zhang2020learning}
\citation{young-etal-2014-image}
\citation{young-etal-2014-image}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Architecture of RTN for acoustic modelling}}{45}{figure.29}\protected@file@percent }
\newlabel{fig:dgp}{{29}{45}{Architecture of RTN for acoustic modelling}{figure.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Learning to Represent Image and Text with Denotation Graph}{45}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{45}{subsection.4.7}\protected@file@percent }
\citation{liu2021retrieval-augmented}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces denotation graph extracted from the FLICKR30K dataset}}{46}{figure.30}\protected@file@percent }
\newlabel{fig:DG}{{30}{46}{denotation graph extracted from the FLICKR30K dataset}{figure.30}{}}
\newlabel{fig:hgnn}{{4.7}{46}{Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{subsection.4.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Overview of HGNN}}{46}{figure.31}\protected@file@percent }
\newlabel{fig:cpg}{{4.7}{47}{Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{figure.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces An Example of Code Property Graph(CPG)}}{47}{figure.32}\protected@file@percent }
\citation{DBLP:journals/corr/NarayananCVCLJ17}
\citation{bai2018convolutional}
\@writefile{toc}{\contentsline {section}{\numberline {5}Graph Similarity}{48}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}graph2vec: Learning Distributed Representation of Graphs}{48}{subsection.5.1}\protected@file@percent }
\newlabel{sec:GSimCNN}{{5.2}{48}{Convolutional Set Macthing for Graph Similarity}{subsection.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Convolutional Set Macthing for Graph Similarity}{48}{subsection.5.2}\protected@file@percent }
\citation{arora2019exact}
\citation{you2018graphrnn}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces GSimCNN的三个阶段，分别用不同颜色的虚线框圈出}}{49}{figure.33}\protected@file@percent }
\newlabel{fig:GSimCNN}{{33}{49}{GSimCNN的三个阶段，分别用不同颜色的虚线框圈出}{figure.33}{}}
\citation{bai2019simgnn}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces 左边的为相似的图的相似矩阵，右边为不相似图的相似矩阵}}{50}{figure.34}\protected@file@percent }
\newlabel{fig:sim}{{34}{50}{左边的为相似的图的相似矩阵，右边为不相似图的相似矩阵}{figure.34}{}}
\newlabel{sec:SimCNN}{{5.3}{50}{SimGNN: A Neural Network Approach to Fast Graph Similarity Computation}{subsection.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}SimGNN: A Neural Network Approach to Fast Graph Similarity Computation}{50}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Strategy 1}{50}{section*.119}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 1}{50}{section*.120}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 2}{50}{section*.121}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces SimGNN}}{51}{figure.35}\protected@file@percent }
\newlabel{fig:SimGNN}{{35}{51}{SimGNN}{figure.35}{}}
\@writefile{toc}{\contentsline {subparagraph}{Stage 3}{51}{section*.122}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 4}{51}{section*.123}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Strategy 2}{51}{section*.124}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{51}{section*.125}\protected@file@percent }
\citation{bai2019unsupervised}
\citation{bai2018convolutional}
\citation{xu2018how}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{52}{section*.126}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Unsupervised Inductive Graph-level Representation Learning via Grpah-Graph proximity}{52}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Overview of UGraphEmb}}{52}{figure.36}\protected@file@percent }
\newlabel{fig:UGraphEmb}{{36}{52}{Overview of UGraphEmb}{figure.36}{}}
\@writefile{toc}{\contentsline {paragraph}{UGraphEmb思路}{52}{section*.127}\protected@file@percent }
\citation{makhzani2016adversarial}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{53}{section*.128}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{53}{section*.129}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Grapg-Graph Similarity Network}{53}{subsection.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Overview of Graph-Graph}}{53}{figure.37}\protected@file@percent }
\newlabel{fig:G2G}{{37}{53}{Overview of Graph-Graph}{figure.37}{}}
\@writefile{toc}{\contentsline {paragraph}{G2G思路}{53}{section*.130}\protected@file@percent }
\citation{ma2020deep}
\@writefile{toc}{\contentsline {subparagraph}{GCN}{54}{section*.131}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Heterogeneous Space Alignment}{54}{section*.132}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Graph-Graph Similarity Network}{54}{section*.133}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{SuperGraph}{54}{section*.134}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{54}{section*.135}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{54}{section*.136}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Deep Graph Similarity Learning: A Survey}{54}{subsection.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Taxonomy of DGS}}{55}{figure.38}\protected@file@percent }
\newlabel{fig:taxonomy_dgs}{{38}{55}{Taxonomy of DGS}{figure.38}{}}
\citation{xu2020hierarchical}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Hierarchical Large-scale Graph Similarity Computation via Graph Coarsening and Matching}{56}{subsection.5.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Overview of COSIM-GNN}}{56}{figure.39}\protected@file@percent }
\newlabel{fig:cosim}{{39}{56}{Overview of COSIM-GNN}{figure.39}{}}
\@writefile{toc}{\contentsline {paragraph}{COSIM-GNN思路}{56}{section*.137}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Embedding}{56}{section*.138}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Coarsening}{56}{section*.139}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Matching}{56}{section*.140}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{56}{section*.141}\protected@file@percent }
\citation{yanardag2015deep}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{57}{section*.142}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Deep Graph Kernels}{57}{subsection.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{使用Graph Kernels计算图相似性}{57}{section*.143}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{思路}{57}{section*.144}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{58}{section*.145}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{58}{section*.146}\protected@file@percent }
\citation{pareja2019evolvegcn}
\@writefile{toc}{\contentsline {section}{\numberline {6}Dynamic Graphs}{59}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs}{59}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{59}{section*.147}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces EvolveGCN}}{59}{figure.40}\protected@file@percent }
\newlabel{fig:evolvegcn}{{40}{59}{EvolveGCN}{figure.40}{}}
\@writefile{toc}{\contentsline {paragraph}{EvolveGCN思路}{59}{section*.148}\protected@file@percent }
\citation{rossi2020temporal}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{60}{section*.149}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{60}{section*.150}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Temporal Graph Networks for Deep Learning on Dynamic Graphs}{60}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{60}{section*.151}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{TGN思路}{60}{section*.152}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Memory}{60}{section*.153}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Message Function}{61}{section*.154}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Message Aggregator}{61}{section*.155}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Memory Updater}{61}{section*.156}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Embeddings}{61}{section*.157}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces TGN}}{61}{figure.41}\protected@file@percent }
\newlabel{fig:tgn}{{41}{61}{TGN}{figure.41}{}}
\citation{tgat_iclr20}
\citation{vaswani2017attention}
\citation{rossi2020temporal}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{62}{section*.158}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Inductive representation learning on Temporal Graphs}{62}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{62}{section*.159}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{TGAT思路}{62}{section*.160}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{self-attention}{62}{section*.161}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{TGAT}{62}{section*.162}\protected@file@percent }
\citation{sankar2020dysat}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces TGAT layer，采用了多头注意力机制，k=3}}{63}{figure.42}\protected@file@percent }
\newlabel{fig:tgat}{{42}{63}{TGAT layer，采用了多头注意力机制，k=3}{figure.42}{}}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{63}{section*.163}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{63}{section*.164}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}DySAT: Deep Neural Representation Learning on Dynamic Graph via Self-Attention Networks}{63}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{63}{section*.165}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{dynamic graph}{63}{section*.166}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces DySAT}}{64}{figure.43}\protected@file@percent }
\newlabel{fig:dysat}{{43}{64}{DySAT}{figure.43}{}}
\@writefile{toc}{\contentsline {paragraph}{DySAT思路}{64}{figure.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Structural Self-Attention}{64}{section*.168}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Temporal Self-Attention}{64}{section*.169}\protected@file@percent }
\citation{yan2018spatial}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{65}{section*.170}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{65}{section*.171}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recogonition}{65}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{65}{section*.172}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ST-GCN思路}{65}{figure.44}\protected@file@percent }
\citation{wang2021inductive}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces ST-GCN}}{66}{figure.44}\protected@file@percent }
\newlabel{fig:st-gcn}{{44}{66}{ST-GCN}{figure.44}{}}
\@writefile{toc}{\contentsline {subparagraph}{Skeleton Graph Construction}{66}{section*.174}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Spatial Graph Convolutional Neural Network}{66}{section*.175}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{66}{section*.176}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{66}{section*.177}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Inductive Representation Learning In Temporal Networks via Causal Anonymous Walks}{66}{subsection.6.6}\protected@file@percent }
\citation{micali2016reconstructing}
\citation{micali2016reconstructing}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{67}{section*.178}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{CAW思路}{67}{section*.179}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Anonymous walks}}{67}{figure.45}\protected@file@percent }
\newlabel{fig:aw}{{45}{67}{Anonymous walks}{figure.45}{}}
\@writefile{toc}{\contentsline {subparagraph}{Causal Anonymous Walk}{67}{section*.180}\protected@file@percent }
\citation{tgat_iclr20}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces CAW}}{68}{figure.46}\protected@file@percent }
\newlabel{fig:caw}{{46}{68}{CAW}{figure.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Temporal Walk Extraction}}{68}{figure.47}\protected@file@percent }
\newlabel{fig:caw-walk-eatraction}{{47}{68}{Temporal Walk Extraction}{figure.47}{}}
\@writefile{toc}{\contentsline {subparagraph}{Neural Encoding for Causal Anonymous Walks}{68}{section*.181}\protected@file@percent }
\citation{shang2021discrete}
\citation{jang2017categorical}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{69}{section*.182}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{69}{section*.183}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}DISCRETE GRAPH STRUCTURE LEARNING FOR FORECASTING MULTIPLE TIME SERIES}{69}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{69}{section*.184}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GTS思路}{69}{figure.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{69}{section*.186}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces GTS Architecture}}{70}{figure.48}\protected@file@percent }
\newlabel{fig:gts}{{48}{70}{GTS Architecture}{figure.48}{}}
\citation{ronneberger2015u-net}
\citation{long2015fully}
\citation{long2015fully}
\@writefile{toc}{\contentsline {section}{\numberline {7}CV}{71}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}U-Net: Convolutional Networks for Biomedical Image Segmentation}{71}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Motivation}{71}{section*.187}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{U-Net}{71}{section*.188}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces U-Net architecture}}{71}{figure.49}\protected@file@percent }
\newlabel{fig:unet}{{49}{71}{U-Net architecture}{figure.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Overlap-tile strategy}}{72}{figure.50}\protected@file@percent }
\newlabel{fig:overlap-tile}{{50}{72}{Overlap-tile strategy}{figure.50}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{72}{section*.189}\protected@file@percent }
\citation{10.1145/219717.219748}
\citation{ryabinin2020embedding}
\citation{mazur2019vector}
\citation{pennington-etal-2014-glove}
\citation{cui2020enhancing}
\@writefile{toc}{\contentsline {section}{\numberline {8}NLP}{73}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Embedding Words in Non-Vector Space with Unsupervised Graph Learning}{73}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks}{73}{subsection.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces Overview of Topic-GraphSum}}{73}{figure.51}\protected@file@percent }
\newlabel{fig:topic_grpah_sum}{{51}{73}{Overview of Topic-GraphSum}{figure.51}{}}
\citation{rendle2010factorization}
\@writefile{toc}{\contentsline {section}{\numberline {9}Recommender System}{75}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Factorization Machines}{75}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{75}{section*.190}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FM}{75}{section*.191}\protected@file@percent }
\newlabel{step0}{{2}{76}{FM}{equation.9.2}{}}
\newlabel{step1}{{3}{76}{FM}{equation.9.3}{}}
\newlabel{step2}{{4}{76}{FM}{equation.9.4}{}}
\newlabel{step3}{{5}{76}{FM}{equation.9.5}{}}
\newlabel{step4}{{6}{76}{FM}{equation.9.6}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{76}{section*.192}\protected@file@percent }
\citation{cheng2016wide}
\citation{mcmahan2011follow-the-regularized-leader}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Wide \& Deep Learning for Recommender Systems}{77}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{77}{section*.193}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces Wide\&Deep}}{77}{figure.52}\protected@file@percent }
\newlabel{fig:wdl}{{52}{77}{Wide\&Deep}{figure.52}{}}
\@writefile{toc}{\contentsline {paragraph}{Wide\&Deep}{77}{figure.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Wide Component}{77}{section*.195}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Deep Component}{77}{section*.196}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Joint of Wide and Deep}{77}{section*.197}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{77}{section*.198}\protected@file@percent }
\citation{covington2016deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Deep Neural Networks for YouTube Recommendations}{78}{subsection.9.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces 推荐系统整体架构}}{78}{figure.53}\protected@file@percent }
\newlabel{fig:recsys}{{53}{78}{推荐系统整体架构}{figure.53}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{78}{section*.199}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{CANDIDATE GENERATION}{78}{section*.200}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Deep candidate generation model architecture}}{79}{figure.54}\protected@file@percent }
\newlabel{fig:can_gen}{{54}{79}{Deep candidate generation model architecture}{figure.54}{}}
\@writefile{toc}{\contentsline {subparagraph}{训练数据的生成}{79}{section*.201}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{特殊的特征}{79}{section*.202}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{RANKING}{79}{section*.203}\protected@file@percent }
\citation{juan2016field-aware}
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Deep ranking network architecture}}{80}{figure.55}\protected@file@percent }
\newlabel{fig:ranking}{{55}{80}{Deep ranking network architecture}{figure.55}{}}
\@writefile{toc}{\contentsline {subparagraph}{特征表示}{80}{section*.204}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{80}{section*.205}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Field-aware Factorization Machines for CTR Prediction}{80}{subsection.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{80}{section*.206}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FFM}{81}{section*.207}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces Training FFM with SGD}}{81}{figure.56}\protected@file@percent }
\newlabel{fig:ffm-sg}{{56}{81}{Training FFM with SGD}{figure.56}{}}
\@writefile{toc}{\contentsline {paragraph}{为什么要field-aware？}{81}{section*.208}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Assign field to feature}{81}{section*.209}\protected@file@percent }
\citation{huifeng2017deepfm}
\@writefile{toc}{\contentsline {paragraph}{总结}{82}{section*.210}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}DeepFM: A Factorization-Machine based Neural Network for CTR Prediction}{82}{subsection.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{82}{section*.211}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DeepFM}{82}{section*.212}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{FM Component}{82}{figure.58}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Deep Component}{82}{figure.59}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces Wide \& deep architecture of DeepFM}}{83}{figure.57}\protected@file@percent }
\newlabel{fig:deepfm}{{57}{83}{Wide \& deep architecture of DeepFM}{figure.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces  The architecture of FM}}{83}{figure.58}\protected@file@percent }
\newlabel{fig:deepfm-fm}{{58}{83}{The architecture of FM}{figure.58}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{83}{section*.215}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.6}Product-based Neural Networks for User Response Prediction}{83}{subsection.9.6}\protected@file@percent }
\citation{qu2016product-based}
\citation{menon2011response}
\citation{anhphuong2015factorization}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces The architecture of DNN}}{84}{figure.59}\protected@file@percent }
\newlabel{fig:deepfm-deep}{{59}{84}{The architecture of DNN}{figure.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces The structure of the embedding layer}}{84}{figure.60}\protected@file@percent }
\newlabel{fig:deepfm-embedding}{{60}{84}{The structure of the embedding layer}{figure.60}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{84}{section*.216}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{PNN}{84}{section*.217}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces Dense Embedding层计算方式}}{85}{figure.61}\protected@file@percent }
\newlabel{fig:embedding}{{61}{85}{Dense Embedding层计算方式}{figure.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces PNN Architecture}}{85}{figure.62}\protected@file@percent }
\newlabel{fig:pnn}{{62}{85}{PNN Architecture}{figure.62}{}}
\@writefile{toc}{\contentsline {paragraph}{关于Product操作}{85}{section*.218}\protected@file@percent }
\citation{du2020personalized}
\@writefile{toc}{\contentsline {paragraph}{总结}{86}{section*.219}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.7}Personalized Video Recommendation Using Rich Contents from Videos}{86}{subsection.9.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{86}{section*.220}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{xxx}{86}{section*.221}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{86}{section*.222}\protected@file@percent }
\citation{piech2015deep}
\@writefile{toc}{\contentsline {section}{\numberline {10}Knowledge Tracing}{87}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Deep Knowledge Tracing}{87}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{87}{section*.223}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DKT}{87}{section*.224}\protected@file@percent }
\citation{nakagawa2019graph-based}
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces Deep Knowledge Tracing}}{88}{figure.63}\protected@file@percent }
\newlabel{fig:dkt}{{63}{88}{Deep Knowledge Tracing}{figure.63}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{88}{section*.225}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Graph-based Knowledge Tracing: Modeling Student Proficiency Using Graph Neural Network}{88}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{88}{section*.226}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GKT}{88}{section*.227}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {64}{\ignorespaces GKT流程}}{89}{figure.64}\protected@file@percent }
\newlabel{fig:gkt}{{64}{89}{GKT流程}{figure.64}{}}
\@writefile{toc}{\contentsline {subparagraph}{工作流程}{89}{section*.228}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{隐式的图结构}{89}{section*.229}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{89}{section*.230}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing}{89}{subsection.10.3}\protected@file@percent }
\citation{youngduck2020towards}
\@writefile{lof}{\contentsline {figure}{\numberline {65}{\ignorespaces Architectures of Previous Methods}}{90}{figure.65}\protected@file@percent }
\newlabel{fig:saint-prev}{{65}{90}{Architectures of Previous Methods}{figure.65}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{90}{figure.65}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{SAINT}{90}{figure.66}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{90}{section*.233}\protected@file@percent }
\citation{long2021tracing}
\@writefile{lof}{\contentsline {figure}{\numberline {66}{\ignorespaces Architecture of SAINT}}{91}{figure.66}\protected@file@percent }
\newlabel{fig:saint}{{66}{91}{Architecture of SAINT}{figure.66}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Tracing Knowledge State with Individual Cognition and Acquisition Estimation}{91}{subsection.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{91}{section*.234}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{IEKT}{91}{section*.235}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 符号说明}}{92}{table.1}\protected@file@percent }
\newlabel{tab:annotation}{{1}{92}{符号说明}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {67}{\ignorespaces The frameworks and details of IEKT}}{92}{figure.67}\protected@file@percent }
\newlabel{fig:iekt}{{67}{92}{The frameworks and details of IEKT}{figure.67}{}}
\citation{wu2021federated}
\@writefile{toc}{\contentsline {paragraph}{总结}{93}{section*.236}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5}Federated Deep Knowledge Tracing}{93}{subsection.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{93}{section*.237}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FDKT}{93}{section*.238}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{93}{section*.239}\protected@file@percent }
\citation{shen2021learning}
\@writefile{lof}{\contentsline {figure}{\numberline {68}{\ignorespaces Federated Deep Knowledge Tracing Framework}}{94}{figure.68}\protected@file@percent }
\newlabel{fig:fdkt}{{68}{94}{Federated Deep Knowledge Tracing Framework}{figure.68}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.6}Learning Process-consistent Knowledge Tracing}{94}{subsection.10.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{94}{section*.240}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{LPKT}{94}{section*.241}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {69}{\ignorespaces The architecture of the LPKT model}}{95}{figure.69}\protected@file@percent }
\newlabel{fig:lpkt}{{69}{95}{The architecture of the LPKT model}{figure.69}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{95}{section*.242}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.7}Overview}{95}{subsection.10.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Knowledge Tracing}{95}{section*.243}\protected@file@percent }
\citation{shen2021learning}
\citation{long2021tracing}
\citation{shen2021learning}
\citation{shen2021learning}
\citation{francesco2020weakly-supervised}
\@writefile{toc}{\contentsline {section}{\numberline {11}Others}{97}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Weakly-Supervised Disentanglement Without Compromises}{97}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{解耦表征}{97}{section*.244}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{97}{section*.245}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Disentangled Representation优点}{97}{section*.246}\protected@file@percent }
\citation{mitrovic2021representation}
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Representation Learning via Invariant Causal Mechanism}{98}{subsection.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{98}{section*.247}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {70}{\ignorespaces Data Generation in Causal interpretation}}{98}{figure.70}\protected@file@percent }
\newlabel{fig:causal}{{70}{98}{Data Generation in Causal interpretation}{figure.70}{}}
\@writefile{toc}{\contentsline {paragraph}{RELIC}{98}{figure.70}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{98}{section*.249}\protected@file@percent }
\citation{tonekaboni2020unsupervised}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}UNSUPERVISED REPRESENTATION LEARNING FOR TIME SERIES WITH TEMPORAL NEIGHBORHOOD CODING}{99}{subsection.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{99}{section*.250}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {71}{\ignorespaces TNC Architecture}}{99}{figure.71}\protected@file@percent }
\newlabel{fig:tnc}{{71}{99}{TNC Architecture}{figure.71}{}}
\@writefile{toc}{\contentsline {paragraph}{TNC思路}{99}{figure.71}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{alon2021on}{1}
\bibcite{anhphuong2015factorization}{2}
\bibcite{arora2019exact}{3}
\bibcite{bai2019simgnn}{4}
\bibcite{bai2019unsupervised}{5}
\bibcite{bai2018convolutional}{6}
\bibcite{6472238}{7}
\bibcite{chen2018fastgcn}{8}
\bibcite{cheng2016wide}{9}
\bibcite{cho2014learning}{10}
\@writefile{toc}{\contentsline {paragraph}{总结}{100}{section*.252}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{100}{section*.253}\protected@file@percent }
\bibcite{covington2016deep}{11}
\bibcite{cui2020enhancing}{12}
\bibcite{tgat_iclr20}{13}
\bibcite{dhillon2007weighted}{14}
\bibcite{doersch2016tutorial}{15}
\bibcite{du2020personalized}{16}
\bibcite{francesco2020weakly-supervised}{17}
\bibcite{goodfellow2014generative}{18}
\bibcite{he2016deep}{19}
\bibcite{dgp}{20}
\bibcite{huang2020combining}{21}
\bibcite{huifeng2017deepfm}{22}
\bibcite{jang2017categorical}{23}
\bibcite{juan2016field-aware}{24}
\bibcite{khasahmadi2020memory-based}{25}
\bibcite{kingma2014auto}{26}
\bibcite{kingma2014autoencoding}{27}
\bibcite{kipf2016variational}{28}
\bibcite{li2019deepgcns}{29}
\bibcite{li2015gated}{30}
\bibcite{li2018learning}{31}
\bibcite{liu2021retrieval-augmented}{32}
\bibcite{long2015fully}{33}
\bibcite{long2021tracing}{34}
\bibcite{ma2020deep}{35}
\bibcite{makhzani2016adversarial}{36}
\bibcite{mao2020expressive}{37}
\bibcite{mazur2019vector}{38}
\bibcite{mcmahan2011follow-the-regularized-leader}{39}
\bibcite{menon2011response}{40}
\bibcite{mesquita2020rethinking}{41}
\bibcite{micali2016reconstructing}{42}
\bibcite{10.1145/219717.219748}{43}
\bibcite{mitrovic2021representation}{44}
\bibcite{nakagawa2019graph-based}{45}
\bibcite{DBLP:journals/corr/NarayananCVCLJ17}{46}
\bibcite{10.1007/3-540-44802-0_1}{47}
\bibcite{pareja2019evolvegcn}{48}
\bibcite{pennington-etal-2014-glove}{49}
\bibcite{piech2015deep}{50}
\bibcite{qu2016product-based}{51}
\bibcite{rendle2010factorization}{52}
\bibcite{ronneberger2015u-net}{53}
\bibcite{rossi2020temporal}{54}
\bibcite{ryabinin2020embedding}{55}
\bibcite{sankar2020dysat}{56}
\bibcite{shang2021discrete}{57}
\bibcite{shen2021learning}{58}
\bibcite{shervashidze2011weisfeiler}{59}
\bibcite{6494675}{60}
\bibcite{simonovsky2018graphvae}{61}
\bibcite{tonekaboni2020unsupervised}{62}
\bibcite{vaswani2017attention}{63}
\bibcite{wan2020contrastive}{64}
\bibcite{SEED_Lichen}{65}
\bibcite{wang2021inductive}{66}
\bibcite{weston2015aicomplete}{67}
\bibcite{wu2021federated}{68}
\bibcite{9046288}{69}
\bibcite{xu2020hierarchical}{70}
\bibcite{xu2018how}{71}
\bibcite{yan2018spatial}{72}
\bibcite{yanardag2015deep}{73}
\bibcite{ying2019hierarchical}{74}
\bibcite{you2020graph}{75}
\bibcite{you2019graph}{76}
\bibcite{you2018graphrnn}{77}
\bibcite{young-etal-2014-image}{78}
\bibcite{youngduck2020towards}{79}
\bibcite{Zeng_2021}{80}
\bibcite{zhang2020learning}{81}
\gdef \@abspage@last{105}
