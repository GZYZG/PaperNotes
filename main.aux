\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{List of Figures}{3}{section*.2}\protected@file@percent }
\citation{you2018graphrnn}
\citation{kingma2014auto}
\citation{goodfellow2014generative}
\citation{simonovsky2018graphvae}
\citation{li2018learning}
\citation{li2018learning}
\@writefile{toc}{\contentsline {section}{\numberline {1}GraphRNN: Generating Realistic Graphs with Deep Auto-Regressive Models}{5}{section.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces GraphRNN inference algorithm }}{6}{algorithm.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces GraphRNN生成图的过程}}{6}{figure.1}\protected@file@percent }
\citation{xu2018how}
\@writefile{toc}{\contentsline {section}{\numberline {2}How powerful are graph gnns?}{8}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 令Mean, Max失败的例子}}{8}{figure.2}\protected@file@percent }
\citation{shervashidze2011weisfeiler}
\@writefile{toc}{\contentsline {paragraph}{MEAN Learns Distributions}{9}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{MAX Identity "Skeleton"}{9}{section*.4}\protected@file@percent }
\citation{li2015gated}
\citation{cho2014learning}
\citation{weston2015aicomplete}
\citation{cho2014learning}
\@writefile{toc}{\contentsline {section}{\numberline {3}Gated Graph Sequence Neural Networks}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GRU(Gated Recurrent Unit)}{10}{section*.5}\protected@file@percent }
\newlabel{fig:lstm_cell}{{3(a)}{10}{Subfigure 3(a)}{subfigure.3.1}{}}
\newlabel{sub@fig:lstm_cell}{{(a)}{10}{Subfigure 3(a)\relax }{subfigure.3.1}{}}
\newlabel{fig:gru_cell}{{3(b)}{10}{Subfigure 3(b)}{subfigure.3.2}{}}
\newlabel{sub@fig:gru_cell}{{(b)}{10}{Subfigure 3(b)\relax }{subfigure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces LSTM 和 GRU cell的内部结构}}{10}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {LSTM cell}}}{10}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GRU cell}}}{10}{figure.3}\protected@file@percent }
\newlabel{fig:cell}{{3}{10}{LSTM 和 GRU cell的内部结构}{figure.3}{}}
\@writefile{toc}{\contentsline {paragraph}{GG-NN}{10}{section*.6}\protected@file@percent }
\citation{10.1007/3-540-44802-0_1}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces GG-NN}}{11}{figure.4}\protected@file@percent }
\newlabel{fig:gg-nn}{{4}{11}{GG-NN}{figure.4}{}}
\@writefile{toc}{\contentsline {paragraph}{GGS-NN}{11}{section*.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces GGS-NN}}{11}{figure.5}\protected@file@percent }
\newlabel{fig:ggs-nn}{{5}{11}{GGS-NN}{figure.5}{}}
\citation{you2020graph}
\@writefile{toc}{\contentsline {section}{\numberline {4}Graph Structure of Neural Networks}{12}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{如何建模NN为图？}{12}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{12}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{12}{section*.10}\protected@file@percent }
\citation{kipf2016variational}
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {section}{\numberline {5}Variational Graph Auto-Encoders}{13}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces VGAE}}{13}{figure.6}\protected@file@percent }
\newlabel{fig:vgae}{{6}{13}{VGAE}{figure.6}{}}
\@writefile{toc}{\contentsline {paragraph}{VGAE思路}{13}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{13}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{13}{section*.13}\protected@file@percent }
\citation{ying2019hierarchical}
\@writefile{toc}{\contentsline {section}{\numberline {6}Hierarchical Graph Representation Learning with Differentiable Pooling}{14}{section.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Overview of DIFFPOOL}}{14}{figure.7}\protected@file@percent }
\newlabel{fig:diffpool}{{7}{14}{Overview of DIFFPOOL}{figure.7}{}}
\@writefile{toc}{\contentsline {paragraph}{DIFFPOOL思路}{14}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{14}{section*.15}\protected@file@percent }
\citation{you2019graph}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{15}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation}{15}{section.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Overview of GCPN}}{15}{figure.8}\protected@file@percent }
\newlabel{fig:gcpn}{{8}{15}{Overview of GCPN}{figure.8}{}}
\@writefile{toc}{\contentsline {paragraph}{GCPN思路}{15}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{15}{section*.18}\protected@file@percent }
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{16}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Auto-Encoding Variational Bayes}{16}{section.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces 有向图模型}}{16}{figure.9}\protected@file@percent }
\newlabel{fig:aevb}{{9}{16}{有向图模型}{figure.9}{}}
\citation{doersch2016tutorial}
\newlabel{eq:kl}{{1}{17}{Auto-Encoding Variational Bayes}{equation.8.1}{}}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{17}{section*.20}\protected@file@percent }
\citation{dgp}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces without vs. with reparameterization}}{18}{figure.10}\protected@file@percent }
\newlabel{fig:vae_rp}{{10}{18}{without vs. with reparameterization}{figure.10}{}}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{18}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Deep Graph random Process for Relational-Thinking-based Speech Recognition}{18}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{18}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DGP 思路}{19}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实现细节}{19}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Deep Graph Random Process}{19}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Coupling of Innumerable Percept Graphs}{19}{section*.26}\protected@file@percent }
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {subparagraph}{Inference and Sampling of Edges of Summary Graph}{20}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Application of DGP for Acoustic Modelling}{20}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Learning}{20}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{20}{section*.30}\protected@file@percent }
\citation{makhzani2016adversarial}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Architecture of RTN for acoustic modelling}}{21}{figure.11}\protected@file@percent }
\newlabel{fig:dgp}{{11}{21}{Architecture of RTN for acoustic modelling}{figure.11}{}}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{21}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Adversarial Autoencoders}{21}{section.10}\protected@file@percent }
\citation{kingma2014autoencoding}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Architecture of AAE}}{22}{figure.12}\protected@file@percent }
\newlabel{fig:AAE}{{12}{22}{Architecture of AAE}{figure.12}{}}
\@writefile{toc}{\contentsline {paragraph}{AAE思路}{22}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{AAE的应用}{22}{section*.33}\protected@file@percent }
\citation{9046288}
\citation{li2015gated}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{23}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{23}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}A Comprehensive Survey on Graph Neural Network}{23}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GNNs分类}{23}{section*.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{RecGNNs}{23}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{ConvGNNs}{24}{section*.38}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces RecGNNs v.s. ConvGNNs}}{24}{figure.13}\protected@file@percent }
\newlabel{fig:recgnns_convgnns}{{13}{24}{RecGNNs v.s. ConvGNNs}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Difference between GCN and GAT}}{25}{figure.14}\protected@file@percent }
\newlabel{fig:gcn_gat}{{14}{25}{Difference between GCN and GAT}{figure.14}{}}
\@writefile{toc}{\contentsline {subparagraph}{GAEs}{25}{section*.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces  Main characteristics of selected GAEs}}{25}{figure.15}\protected@file@percent }
\newlabel{fig:gaes}{{15}{25}{Main characteristics of selected GAEs}{figure.15}{}}
\@writefile{toc}{\contentsline {subparagraph}{STGNNs}{25}{section*.40}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GNNs应用}{26}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Computer Vision}{26}{section*.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Natural Language Processing}{26}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Traffic}{26}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Recommender system}{26}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Chemistry}{26}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Others}{26}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GNNs模型评估}{26}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{常用数据集}{26}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{未来发展方向}{26}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Model Depth}{26}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Scalability trade-off}{26}{section*.52}\protected@file@percent }
\citation{6494675}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Summary of benchmark datasets}}{27}{figure.16}\protected@file@percent }
\newlabel{fig:benchmark}{{16}{27}{Summary of benchmark datasets}{figure.16}{}}
\@writefile{toc}{\contentsline {subparagraph}{Hetergenity}{27}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Dynamicity}{27}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}The Emerging Field of Signal Processing on Graphs}{27}{section.12}\protected@file@percent }
\citation{mesquita2020rethinking}
\citation{dhillon2007weighted}
\citation{ying2019hierarchical}
\citation{khasahmadi2020memory-based}
\@writefile{toc}{\contentsline {section}{\numberline {13}Rethinking pooling in graph neural networks}{28}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{28}{section*.55}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Rethinking思路}{28}{section*.56}\protected@file@percent }
\citation{chen2018fastgcn}
\citation{francesco2020weakly-supervised}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{29}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{29}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14}FASTGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling}{29}{section.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15}Weakly-Supervised Disentanglement Without Compromises}{29}{section.15}\protected@file@percent }
\citation{6472238}
\@writefile{toc}{\contentsline {paragraph}{解耦表征}{30}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{30}{section*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Disentangled Representation优点}{30}{section*.61}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16}Representation Learning: A Review and New Perspectives}{30}{section.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{表征学习的应用}{31}{section*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{语音识别与信号处理}{31}{section*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{目标识别}{31}{section*.64}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{自然语言处理}{31}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{多任务学习、迁移学习、领域适应}{31}{section*.66}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{表征学习中的Priors}{31}{section*.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Smothness}{31}{section*.68}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Multiple explanatory factors}{31}{section*.69}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{A hierarchical organization of explanatory factors}{31}{section*.70}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Semi-supervised learning}{31}{section*.71}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Shared factors across tasks}{31}{section*.72}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Manifold}{31}{section*.73}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Natural clustering}{31}{section*.74}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Temporal and spatial coherence}{31}{section*.75}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Sparsity}{31}{section*.76}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Simplicity of factor dependencies}{31}{section*.77}\protected@file@percent }
\citation{wan2020contrastive}
\@writefile{toc}{\contentsline {paragraph}{What makes a Representation Good?}{32}{section*.78}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Distributed representation}{32}{section*.79}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Depth and Abstraction}{32}{section*.80}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Disentangling Factors of Variation}{32}{section*.81}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Good Criteria for Learning Representation?}{32}{section*.82}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17}Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning}{32}{section.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{32}{section*.83}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{思路}{32}{figure.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces CG3}}{33}{figure.17}\protected@file@percent }
\newlabel{fig:cg3}{{17}{33}{CG3}{figure.17}{}}
\@writefile{toc}{\contentsline {subparagraph}{Semi-Supervised Contrastive Learning}{33}{section*.85}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Graph Generative Loss}{33}{section*.86}\protected@file@percent }
\citation{SEED_Lichen}
\@writefile{toc}{\contentsline {subparagraph}{Model Training}{34}{section*.87}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{34}{section*.88}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{34}{section*.89}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {18}Inductive and Unsupervised Representation Learning on Graph Structured Objects}{34}{section.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{34}{section*.90}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces SEED}}{34}{figure.18}\protected@file@percent }
\newlabel{fig:seed}{{18}{34}{SEED}{figure.18}{}}
\@writefile{toc}{\contentsline {paragraph}{SEED思路}{34}{figure.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Sampling}{35}{section*.92}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces WEAVE与随机游走对比}}{35}{figure.19}\protected@file@percent }
\newlabel{fig:weave}{{19}{35}{WEAVE与随机游走对比}{figure.19}{}}
\@writefile{toc}{\contentsline {subparagraph}{Encoding}{35}{section*.93}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Embedding Distribution}{35}{section*.94}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{35}{section*.95}\protected@file@percent }
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{36}{section*.96}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {19}Attention is All you need}{36}{section.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{36}{section*.97}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transformer}{36}{figure.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Encoder and Decoder}{36}{section*.99}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Transformer Architecture}}{37}{figure.20}\protected@file@percent }
\newlabel{fig:transformer}{{20}{37}{Transformer Architecture}{figure.20}{}}
\@writefile{toc}{\contentsline {subparagraph}{Attention}{37}{section*.100}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Scaled Dot-Production Attention与Multi-Head Attention}}{38}{figure.21}\protected@file@percent }
\newlabel{fig:scaled dot-product attention and multi-head attention}{{21}{38}{Scaled Dot-Production Attention与Multi-Head Attention}{figure.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Self-Attention}{38}{section*.101}\protected@file@percent }
\newlabel{rnn-cnn-attention}{{19}{38}{Why Self-Attention}{section*.101}{}}
\citation{he2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces CNN、Attention、Multi-head Attention}}{39}{figure.22}\protected@file@percent }
\newlabel{fig:cnn-attention-multi head}{{22}{39}{CNN、Attention、Multi-head Attention}{figure.22}{}}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{39}{section*.102}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Attention参考资料}{39}{section*.103}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {20}Deep Residual Learning for Image Recognition}{39}{section.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{39}{section*.104}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Degradation}}{40}{figure.23}\protected@file@percent }
\newlabel{fig:degradation}{{23}{40}{Degradation}{figure.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Residual learning: a building block}}{40}{figure.24}\protected@file@percent }
\newlabel{fig:residual}{{24}{40}{Residual learning: a building block}{figure.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Residual Learning}{40}{figure.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的问题/优势}{40}{section*.106}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{40}{section*.107}\protected@file@percent }
\citation{li2019deepgcns}
\citation{he2016deep}
\@writefile{toc}{\contentsline {section}{\numberline {21}DeepGCNs: Can GCNs Go as Deep as CNNs?}{41}{section.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Traing deep GCNs}}{41}{figure.25}\protected@file@percent }
\newlabel{fig:traing_deep_gcns}{{25}{41}{Traing deep GCNs}{figure.25}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{41}{figure.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DeepGCN}{41}{section*.109}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Residual Learning for GCNs}{41}{section*.110}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Dense Connections in GCNs}{42}{section*.111}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Dilated Aggregation inn GCNs}{42}{section*.112}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Dilated Convolution in GCNs}}{42}{figure.26}\protected@file@percent }
\newlabel{figz:dilated_convolution_in_gcns}{{26}{42}{Dilated Convolution in GCNs}{figure.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces DeepGCN}}{42}{figure.27}\protected@file@percent }
\newlabel{figz:deepgcn}{{27}{42}{DeepGCN}{figure.27}{}}
\citation{huang2020combining}
\@writefile{toc}{\contentsline {paragraph}{总结}{43}{section*.113}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {22}Combining Label Propagation and Simple Models OUT-PERFORMS Graph Networks}{43}{section.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{43}{section*.114}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Correct and Smooth}{43}{section*.115}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Simple Base Predictor}{43}{section*.116}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Correct error in base prediction with Residual Propagation}{43}{section*.117}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Correct and Smooth}}{44}{figure.28}\protected@file@percent }
\newlabel{fig:C&S}{{28}{44}{Correct and Smooth}{figure.28}{}}
\@writefile{toc}{\contentsline {subparagraph}{Smoothing final prediction with Prediction Correlation}{44}{section*.118}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{44}{section*.119}\protected@file@percent }
\citation{alon2021on}
\citation{li2019deepgcns}
\@writefile{toc}{\contentsline {section}{\numberline {23}On the Bottleneck of Graph Neural Networks And Practical Implcation}{45}{section.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces The bottlenecks of Seq2seq and GNN models}}{45}{figure.29}\protected@file@percent }
\newlabel{fig:bottleneck}{{29}{45}{The bottlenecks of Seq2seq and GNN models}{figure.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Over Suqashing}{45}{figure.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{45}{section*.121}\protected@file@percent }
\citation{mitrovic2021representation}
\citation{kingma2014autoencoding}
\@writefile{toc}{\contentsline {section}{\numberline {24}Representation Learning via Invariant Causal Mechanism}{46}{section.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{46}{section*.122}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Data Generation in Causal interpretation}}{46}{figure.30}\protected@file@percent }
\newlabel{fig:causal}{{30}{46}{Data Generation in Causal interpretation}{figure.30}{}}
\@writefile{toc}{\contentsline {paragraph}{RELIC}{46}{figure.30}\protected@file@percent }
\citation{ronneberger2015u-net}
\citation{long2015fully}
\citation{long2015fully}
\@writefile{toc}{\contentsline {paragraph}{总结}{47}{section*.124}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {25}U-Net: Convolutional Networks for Biomedical Image Segmentation}{47}{section.25}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Motivation}{47}{section*.125}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{U-Net}{47}{section*.126}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces U-Net architecture}}{48}{figure.31}\protected@file@percent }
\newlabel{fig:unet}{{31}{48}{U-Net architecture}{figure.31}{}}
\@writefile{toc}{\contentsline {paragraph}{总结}{48}{section*.127}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {26}UNSUPERVISED REPRESENTATION LEARNING FOR TIME SERIES WITH TEMPORAL NEIGHBORHOOD CODING}{48}{section.26}\protected@file@percent }
\citation{tonekaboni2020unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Overlap-tile strategy}}{49}{figure.32}\protected@file@percent }
\newlabel{fig:overlap-tile}{{32}{49}{Overlap-tile strategy}{figure.32}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{49}{section*.128}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces TNC Architecture}}{49}{figure.33}\protected@file@percent }
\newlabel{fig:tnc}{{33}{49}{TNC Architecture}{figure.33}{}}
\@writefile{toc}{\contentsline {paragraph}{TNC思路}{49}{figure.33}\protected@file@percent }
\citation{DBLP:journals/corr/NarayananCVCLJ17}
\@writefile{toc}{\contentsline {paragraph}{总结}{50}{section*.130}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {27}Graph Similarity}{50}{section.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.1}graph2vec: Learning Distributed Representation of Graphs}{50}{subsection.27.1}\protected@file@percent }
\citation{bai2018convolutional}
\newlabel{sec:GSimCNN}{{27.2}{51}{Convolutional Set Macthing for Graph Similarity}{subsection.27.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {27.2}Convolutional Set Macthing for Graph Similarity}{51}{subsection.27.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces GSimCNN的三个阶段，分别用不同颜色的虚线框圈出}}{51}{figure.34}\protected@file@percent }
\newlabel{fig:GSimCNN}{{34}{51}{GSimCNN的三个阶段，分别用不同颜色的虚线框圈出}{figure.34}{}}
\citation{arora2019exact}
\citation{you2018graphrnn}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces 左边的为相似的图的相似矩阵，右边为不相似图的相似矩阵}}{52}{figure.35}\protected@file@percent }
\newlabel{fig:sim}{{35}{52}{左边的为相似的图的相似矩阵，右边为不相似图的相似矩阵}{figure.35}{}}
\citation{bai2019simgnn}
\newlabel{sec:SimCNN}{{27.3}{53}{SimGNN: A Neural Network Approach to Fast Graph Similarity Computation}{subsection.27.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {27.3}SimGNN: A Neural Network Approach to Fast Graph Similarity Computation}{53}{subsection.27.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces SimGNN}}{53}{figure.36}\protected@file@percent }
\newlabel{fig:SimGNN}{{36}{53}{SimGNN}{figure.36}{}}
\@writefile{toc}{\contentsline {paragraph}{Strategy 1}{53}{section*.131}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 1}{53}{section*.132}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 2}{53}{section*.133}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 3}{54}{section*.134}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Stage 4}{54}{section*.135}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Strategy 2}{54}{section*.136}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{54}{section*.137}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{54}{section*.138}\protected@file@percent }
\citation{bai2019unsupervised}
\citation{bai2018convolutional}
\citation{xu2018how}
\@writefile{toc}{\contentsline {subsection}{\numberline {27.4}Unsupervised Inductive Graph-level Representation Learning via Grpah-Graph proximity}{55}{subsection.27.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Overview of UGraphEmb}}{55}{figure.37}\protected@file@percent }
\newlabel{fig:UGraphEmb}{{37}{55}{Overview of UGraphEmb}{figure.37}{}}
\@writefile{toc}{\contentsline {paragraph}{UGraphEmb思路}{55}{section*.139}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{55}{section*.140}\protected@file@percent }
\citation{makhzani2016adversarial}
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{56}{section*.141}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.5}Grapg-Graph Similarity Network}{56}{subsection.27.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Overview of Graph-Graph}}{56}{figure.38}\protected@file@percent }
\newlabel{fig:G2G}{{38}{56}{Overview of Graph-Graph}{figure.38}{}}
\@writefile{toc}{\contentsline {paragraph}{G2G思路}{56}{section*.142}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{GCN}{56}{section*.143}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Heterogeneous Space Alignment}{56}{section*.144}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Graph-Graph Similarity Network}{56}{section*.145}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{SuperGraph}{56}{section*.146}\protected@file@percent }
\citation{ma2020deep}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{57}{section*.147}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{57}{section*.148}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.6}Deep Graph Similarity Learning: A Survey}{57}{subsection.27.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Taxonomy of DGS}}{57}{figure.39}\protected@file@percent }
\newlabel{fig:taxonomy_dgs}{{39}{57}{Taxonomy of DGS}{figure.39}{}}
\citation{xu2020hierarchical}
\@writefile{toc}{\contentsline {subsection}{\numberline {27.7}Hierarchical Large-scale Graph Similarity Computation via Graph Coarsening and Matching}{58}{subsection.27.7}\protected@file@percent }
\citation{yanardag2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Overview of COSIM-GNN}}{59}{figure.40}\protected@file@percent }
\newlabel{fig:cosim}{{40}{59}{Overview of COSIM-GNN}{figure.40}{}}
\@writefile{toc}{\contentsline {paragraph}{COSIM-GNN思路}{59}{section*.149}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Embedding}{59}{section*.150}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Coarsening}{59}{section*.151}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Matching}{59}{section*.152}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{59}{section*.153}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{59}{section*.154}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.8}Deep Graph Kernels}{59}{subsection.27.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{使用Graph Kernels计算图相似性}{60}{section*.155}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{思路}{60}{section*.156}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{60}{section*.157}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{60}{section*.158}\protected@file@percent }
\citation{pareja2019evolvegcn}
\@writefile{toc}{\contentsline {section}{\numberline {28}Dynamic Graphs}{61}{section.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.1}EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs}{61}{subsection.28.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{61}{section*.159}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces EvolveGCN}}{61}{figure.41}\protected@file@percent }
\newlabel{fig:evolvegcn}{{41}{61}{EvolveGCN}{figure.41}{}}
\@writefile{toc}{\contentsline {paragraph}{EvolveGCN思路}{61}{section*.160}\protected@file@percent }
\citation{rossi2020temporal}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{62}{section*.161}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{62}{section*.162}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.2}Temporal Graph Networks for Deep Learning on Dynamic Graphs}{62}{subsection.28.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{62}{section*.163}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{TGN思路}{62}{section*.164}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Memory}{62}{section*.165}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Message Function}{63}{section*.166}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Message Aggregator}{63}{section*.167}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Memory Updater}{63}{section*.168}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Embeddings}{63}{section*.169}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces TGN}}{63}{figure.42}\protected@file@percent }
\newlabel{fig:tgn}{{42}{63}{TGN}{figure.42}{}}
\citation{tgat_iclr20}
\citation{vaswani2017attention}
\citation{rossi2020temporal}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{64}{section*.170}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.3}Inductive representation learning on Temporal Graphs}{64}{subsection.28.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{64}{section*.171}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{TGAT思路}{64}{section*.172}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{self-attention}{64}{section*.173}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{TGAT}{64}{section*.174}\protected@file@percent }
\citation{sankar2020dysat}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces TGAT layer，采用了多头注意力机制，k=3}}{65}{figure.43}\protected@file@percent }
\newlabel{fig:tgat}{{43}{65}{TGAT layer，采用了多头注意力机制，k=3}{figure.43}{}}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{65}{section*.175}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{65}{section*.176}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.4}DySAT: Deep Neural Representation Learning on Dynamic Graph via Self-Attention Networks}{65}{subsection.28.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{65}{section*.177}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{dynamic graph}{65}{section*.178}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces DySAT}}{66}{figure.44}\protected@file@percent }
\newlabel{fig:dysat}{{44}{66}{DySAT}{figure.44}{}}
\@writefile{toc}{\contentsline {paragraph}{DySAT思路}{66}{figure.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Structural Self-Attention}{66}{section*.180}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Temporal Self-Attention}{66}{section*.181}\protected@file@percent }
\citation{yan2018spatial}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{67}{section*.182}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{67}{section*.183}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.5}Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recogonition}{67}{subsection.28.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{67}{section*.184}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ST-GCN思路}{67}{figure.45}\protected@file@percent }
\citation{wang2021inductive}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces ST-GCN}}{68}{figure.45}\protected@file@percent }
\newlabel{fig:st-gcn}{{45}{68}{ST-GCN}{figure.45}{}}
\@writefile{toc}{\contentsline {subparagraph}{Skeleton Graph Construction}{68}{section*.186}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Spatial Graph Convolutional Neural Network}{68}{section*.187}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{68}{section*.188}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{68}{section*.189}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.6}Inductive Representation Learning In Temporal Networks via Causal Anonymous Walks}{68}{subsection.28.6}\protected@file@percent }
\citation{micali2016reconstructing}
\citation{micali2016reconstructing}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{69}{section*.190}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{CAW思路}{69}{section*.191}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Anonymous walks}}{69}{figure.46}\protected@file@percent }
\newlabel{fig:aw}{{46}{69}{Anonymous walks}{figure.46}{}}
\@writefile{toc}{\contentsline {subparagraph}{Causal Anonymous Walk}{69}{section*.192}\protected@file@percent }
\citation{tgat_iclr20}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces CAW}}{70}{figure.47}\protected@file@percent }
\newlabel{fig:caw}{{47}{70}{CAW}{figure.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Temporal Walk Extraction}}{70}{figure.48}\protected@file@percent }
\newlabel{fig:caw-walk-eatraction}{{48}{70}{Temporal Walk Extraction}{figure.48}{}}
\@writefile{toc}{\contentsline {subparagraph}{Neural Encoding for Causal Anonymous Walks}{70}{section*.193}\protected@file@percent }
\citation{shang2021discrete}
\@writefile{toc}{\contentsline {paragraph}{方法解决的问题/优势}{71}{section*.194}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{方法的局限性/未来方向}{71}{section*.195}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.7}DISCRETE GRAPH STRUCTURE LEARNING FOR FORECASTING MULTIPLE TIME SERIES}{71}{subsection.28.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{71}{section*.196}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {49}{\ignorespaces GTS Architecture}}{71}{figure.49}\protected@file@percent }
\newlabel{fig:gts}{{49}{71}{GTS Architecture}{figure.49}{}}
\citation{jang2017categorical}
\citation{rendle2010factorization}
\@writefile{toc}{\contentsline {paragraph}{GTS思路}{72}{figure.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{72}{section*.198}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {29}Recommender System}{72}{section.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.1}Factorization Machines}{72}{subsection.29.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{72}{section*.199}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FM}{72}{section*.200}\protected@file@percent }
\newlabel{step0}{{2}{73}{FM}{equation.29.2}{}}
\newlabel{step1}{{3}{73}{FM}{equation.29.3}{}}
\newlabel{step2}{{4}{73}{FM}{equation.29.4}{}}
\newlabel{step3}{{5}{73}{FM}{equation.29.5}{}}
\newlabel{step4}{{6}{73}{FM}{equation.29.6}{}}
\citation{cheng2016wide}
\citation{mcmahan2011follow-the-regularized-leader}
\@writefile{toc}{\contentsline {paragraph}{总结}{74}{section*.201}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.2}Wide \& Deep Learning for Recommender Systems}{74}{subsection.29.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{74}{section*.202}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {50}{\ignorespaces Wide\&Deep}}{74}{figure.50}\protected@file@percent }
\newlabel{fig:wdl}{{50}{74}{Wide\&Deep}{figure.50}{}}
\@writefile{toc}{\contentsline {paragraph}{Wide\&Deep}{74}{figure.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Wide Component}{74}{section*.204}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Deep Component}{74}{section*.205}\protected@file@percent }
\citation{covington2016deep}
\@writefile{toc}{\contentsline {subparagraph}{Joint of Wide and Deep}{75}{section*.206}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{75}{section*.207}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.3}Deep Neural Networks for YouTube Recommendations}{75}{subsection.29.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {51}{\ignorespaces 推荐系统整体架构}}{75}{figure.51}\protected@file@percent }
\newlabel{fig:recsys}{{51}{75}{推荐系统整体架构}{figure.51}{}}
\@writefile{toc}{\contentsline {paragraph}{问题定义}{75}{section*.208}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{CANDIDATE GENERATION}{76}{section*.209}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {52}{\ignorespaces Deep candidate generation model architecture}}{76}{figure.52}\protected@file@percent }
\newlabel{fig:can_gen}{{52}{76}{Deep candidate generation model architecture}{figure.52}{}}
\@writefile{toc}{\contentsline {subparagraph}{训练数据的生成}{76}{section*.210}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{特殊的特征}{76}{section*.211}\protected@file@percent }
\citation{juan2016field-aware}
\@writefile{toc}{\contentsline {paragraph}{RANKING}{77}{section*.212}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {53}{\ignorespaces Deep ranking network architecture}}{77}{figure.53}\protected@file@percent }
\newlabel{fig:ranking}{{53}{77}{Deep ranking network architecture}{figure.53}{}}
\@writefile{toc}{\contentsline {subparagraph}{特征表示}{77}{section*.213}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{77}{section*.214}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.4}Field-aware Factorization Machines for CTR Prediction}{77}{subsection.29.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{78}{section*.215}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FFM}{78}{section*.216}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {54}{\ignorespaces Training FFM with SGD}}{78}{figure.54}\protected@file@percent }
\newlabel{fig:ffm-sg}{{54}{78}{Training FFM with SGD}{figure.54}{}}
\@writefile{toc}{\contentsline {paragraph}{为什么要field-aware？}{78}{section*.217}\protected@file@percent }
\citation{huifeng2017deepfm}
\@writefile{toc}{\contentsline {paragraph}{Assign field to feature}{79}{section*.218}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{79}{section*.219}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.5}DeepFM: A Factorization-Machine based Neural Network for CTR Prediction}{79}{subsection.29.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{问题定义}{79}{section*.220}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{DeepFM}{79}{section*.221}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{FM Component}{79}{figure.56}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {55}{\ignorespaces Wide \& deep architecture of DeepFM}}{80}{figure.55}\protected@file@percent }
\newlabel{fig:deepfm}{{55}{80}{Wide \& deep architecture of DeepFM}{figure.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {56}{\ignorespaces  The architecture of FM}}{80}{figure.56}\protected@file@percent }
\newlabel{fig:deepfm-fm}{{56}{80}{The architecture of FM}{figure.56}{}}
\@writefile{toc}{\contentsline {subparagraph}{Deep Component}{80}{figure.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{总结}{80}{section*.224}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {57}{\ignorespaces The architecture of DNN}}{81}{figure.57}\protected@file@percent }
\newlabel{fig:deepfm-deep}{{57}{81}{The architecture of DNN}{figure.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {58}{\ignorespaces The structure of the embedding layer}}{81}{figure.58}\protected@file@percent }
\newlabel{fig:deepfm-embedding}{{58}{81}{The structure of the embedding layer}{figure.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {59}{\ignorespaces Dense Embedding层计算方式}}{81}{figure.59}\protected@file@percent }
\newlabel{fig:embedding}{{59}{81}{Dense Embedding层计算方式}{figure.59}{}}
\citation{10.1145/219717.219748}
\citation{ryabinin2020embedding}
\citation{mazur2019vector}
\citation{pennington-etal-2014-glove}
\citation{Zeng_2021}
\citation{zhang2020learning}
\citation{young-etal-2014-image}
\citation{young-etal-2014-image}
\@writefile{toc}{\contentsline {section}{\numberline {30}简读论文}{82}{section.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.1}Embedding Words in Non-Vector Space with Unsupervised Graph Learning}{82}{subsection.30.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.2}Accurate, Efficient and Scalable Training of Graph Neural Networks}{82}{subsection.30.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.3}Learning to Represent Image and Text with Denotation Graph}{82}{subsection.30.3}\protected@file@percent }
\citation{mao2020expressive}
\citation{cui2020enhancing}
\@writefile{lof}{\contentsline {figure}{\numberline {60}{\ignorespaces denotation graph extracted from the FLICKR30K dataset}}{83}{figure.60}\protected@file@percent }
\newlabel{fig:DG}{{60}{83}{denotation graph extracted from the FLICKR30K dataset}{figure.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {30.4}Towards Expressive Graph Representation}{83}{subsection.30.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.5}Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks}{83}{subsection.30.5}\protected@file@percent }
\citation{liu2021retrieval-augmented}
\@writefile{lof}{\contentsline {figure}{\numberline {61}{\ignorespaces Overview of Topic-GraphSum}}{84}{figure.61}\protected@file@percent }
\newlabel{fig:topic_grpah_sum}{{61}{84}{Overview of Topic-GraphSum}{figure.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {30.6}Editing Graphs to Satisfy Diversity Requirements}{84}{subsection.30.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.7}On the exact computation of the graph edit distance}{84}{subsection.30.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.8}Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{84}{subsection.30.8}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{alon2021on}{1}
\bibcite{arora2019exact}{2}
\bibcite{bai2019simgnn}{3}
\bibcite{bai2019unsupervised}{4}
\bibcite{bai2018convolutional}{5}
\newlabel{fig:hgnn}{{30.8}{85}{Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{subsection.30.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {62}{\ignorespaces Overview of HGNN}}{85}{figure.62}\protected@file@percent }
\newlabel{fig:cpg}{{30.8}{85}{Retrieval-Augmented Generation for Code Summarization via Hybrid GNN}{figure.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {63}{\ignorespaces An Example of Code Property Graph(CPG)}}{85}{figure.63}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{85}{section*.225}\protected@file@percent }
\bibcite{6472238}{6}
\bibcite{chen2018fastgcn}{7}
\bibcite{cheng2016wide}{8}
\bibcite{cho2014learning}{9}
\bibcite{covington2016deep}{10}
\bibcite{cui2020enhancing}{11}
\bibcite{tgat_iclr20}{12}
\bibcite{dhillon2007weighted}{13}
\bibcite{doersch2016tutorial}{14}
\bibcite{francesco2020weakly-supervised}{15}
\bibcite{goodfellow2014generative}{16}
\bibcite{he2016deep}{17}
\bibcite{dgp}{18}
\bibcite{huang2020combining}{19}
\bibcite{huifeng2017deepfm}{20}
\bibcite{jang2017categorical}{21}
\bibcite{juan2016field-aware}{22}
\bibcite{khasahmadi2020memory-based}{23}
\bibcite{kingma2014auto}{24}
\bibcite{kingma2014autoencoding}{25}
\bibcite{kipf2016variational}{26}
\bibcite{li2019deepgcns}{27}
\bibcite{li2015gated}{28}
\bibcite{li2018learning}{29}
\bibcite{liu2021retrieval-augmented}{30}
\bibcite{long2015fully}{31}
\bibcite{ma2020deep}{32}
\bibcite{makhzani2016adversarial}{33}
\bibcite{mao2020expressive}{34}
\bibcite{mazur2019vector}{35}
\bibcite{mcmahan2011follow-the-regularized-leader}{36}
\bibcite{mesquita2020rethinking}{37}
\bibcite{micali2016reconstructing}{38}
\bibcite{10.1145/219717.219748}{39}
\bibcite{mitrovic2021representation}{40}
\bibcite{DBLP:journals/corr/NarayananCVCLJ17}{41}
\bibcite{10.1007/3-540-44802-0_1}{42}
\bibcite{pareja2019evolvegcn}{43}
\bibcite{pennington-etal-2014-glove}{44}
\bibcite{rendle2010factorization}{45}
\bibcite{ronneberger2015u-net}{46}
\bibcite{rossi2020temporal}{47}
\bibcite{ryabinin2020embedding}{48}
\bibcite{sankar2020dysat}{49}
\bibcite{shang2021discrete}{50}
\bibcite{shervashidze2011weisfeiler}{51}
\bibcite{6494675}{52}
\bibcite{simonovsky2018graphvae}{53}
\bibcite{tonekaboni2020unsupervised}{54}
\bibcite{vaswani2017attention}{55}
\bibcite{wan2020contrastive}{56}
\bibcite{SEED_Lichen}{57}
\bibcite{wang2021inductive}{58}
\bibcite{weston2015aicomplete}{59}
\bibcite{9046288}{60}
\bibcite{xu2020hierarchical}{61}
\bibcite{xu2018how}{62}
\bibcite{yan2018spatial}{63}
\bibcite{yanardag2015deep}{64}
\bibcite{ying2019hierarchical}{65}
\bibcite{you2020graph}{66}
\bibcite{you2019graph}{67}
\bibcite{you2018graphrnn}{68}
\bibcite{young-etal-2014-image}{69}
\bibcite{Zeng_2021}{70}
\bibcite{zhang2020learning}{71}
\gdef \@abspage@last{90}
